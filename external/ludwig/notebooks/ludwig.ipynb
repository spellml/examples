{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ludwig-demo\n",
    "\n",
    "This notebook is a quick demo demonstrating the basic flow for training a machine learning model using Ludwig."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting the data\n",
    "\n",
    "For the purposes of this demo we will use the [Wine Reviews](https://www.kaggle.com/zynicide/wine-reviews) dataset on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine-reviews.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "Archive:  wine-reviews.zip\n",
      "  inflating: /mnt/wine-reviews/winemag-data-130k-v2.csv  \n",
      "  inflating: /mnt/wine-reviews/winemag-data-130k-v2.json  \n",
      "  inflating: /mnt/wine-reviews/winemag-data_first150k.csv  \n"
     ]
    }
   ],
   "source": [
    "!../scripts/download_data.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wine reviews dataset contains two fields of interest for this demo. The first is the `description`, a textual review of the wine. The second is the `points`, a value between 0 and 100. In this demo we will feed the contents of the `description` field to the model as the input, and train it to return the `points` it received as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",country,description,designation,points,price,province,region_1,region_2,variety,winery\n",
      "0,US,\"This tremendous 100% varietal wine hails from Oakville and was aged over three years in oak. Juicy red-cherry fruit and a compelling hint of caramel greet the palate, framed by elegant, fine tannins and a subtle minty tone in the background. Balanced and rewarding from start to finish, it has years ahead of it to develop further nuance. Enjoy 2022–2030.\",Martha's Vineyard,96,235.0,California,Napa Valley,Napa,Cabernet Sauvignon,Heitz\n"
     ]
    }
   ],
   "source": [
    "!head -n 2 /mnt/wine-reviews/winemag-data_first150k.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model configuration\n",
    "\n",
    "Models in Ludwig are configured using a configuration document in YAML syntax. The optimization options get to be pretty deep, and we won't cover them here. We'll just use the default paramaters and model architecture for our given problem.\n",
    "\n",
    "At runtime, Ludwig figures out what model architecture to use by looking at the combination of input and output features stated in the configuration file. This abstracts away model design from the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../datasets/\n",
    "!mkdir ../datasets/wine_reviews/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../datasets/wine_reviews/cfg.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../datasets/wine_reviews/cfg.yaml\n",
    "input_features:\n",
    "    -\n",
    "        name: description\n",
    "        type: text\n",
    "\n",
    "output_features:\n",
    "    -\n",
    "        name: points\n",
    "        type: numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-17 02:42:13.889460: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "███████████████████████\n",
      "█ █ █ █  ▜█ █ █ █ █   █\n",
      "█ █ █ █ █ █ █ █ █ █ ███\n",
      "█ █   █ █ █ █ █ █ █ ▌ █\n",
      "█ █████ █ █ █ █ █ █ █ █\n",
      "█     █  ▟█     █ █   █\n",
      "███████████████████████\n",
      "ludwig v0.3.1 - Train\n",
      "\n",
      "2020-12-17 02:42:14.730667: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2020-12-17 02:42:14.789719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-12-17 02:42:14.790584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2020-12-17 02:42:14.790622: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-12-17 02:42:14.867438: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2020-12-17 02:42:14.906664: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2020-12-17 02:42:14.914786: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2020-12-17 02:42:14.995199: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-12-17 02:42:15.003309: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-12-17 02:42:15.134884: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-12-17 02:42:15.135122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-12-17 02:42:15.136238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-12-17 02:42:15.137179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "Experiment name: wine_reviews_initial_0_experiment\n",
      "Model name: wine_reviews_initial_0_model\n",
      "Output directory: results/wine_reviews_initial_0_experiment_wine_reviews_initial_0_model\n",
      "\n",
      "\n",
      "ludwig_version: '0.3.1'\n",
      "command: ('/usr/local/bin/ludwig train --experiment_name '\n",
      " 'wine_reviews_initial_0_experiment --model_name wine_reviews_initial_0_model '\n",
      " '--config_file ../datasets/wine_reviews/cfg.yaml --dataset '\n",
      " '/mnt/wine-reviews/winemag-data_first150k.csv')\n",
      "random_seed: 42\n",
      "dataset: '/mnt/wine-reviews/winemag-data_first150k.csv'\n",
      "data_format: 'csv'\n",
      "config: {   'combiner': {'type': 'concat'},\n",
      "    'input_features': [   {   'encoder': 'parallel_cnn',\n",
      "                              'level': 'word',\n",
      "                              'name': 'description',\n",
      "                              'tied': None,\n",
      "                              'type': 'text'}],\n",
      "    'output_features': [   {   'clip': None,\n",
      "                               'dependencies': [],\n",
      "                               'loss': {   'type': 'mean_squared_error',\n",
      "                                           'weight': 1},\n",
      "                               'name': 'points',\n",
      "                               'reduce_dependencies': 'sum',\n",
      "                               'reduce_input': 'sum',\n",
      "                               'type': 'numerical'}],\n",
      "    'preprocessing': {   'audio': {   'audio_feature': {'type': 'raw'},\n",
      "                                      'audio_file_length_limit_in_s': 7.5,\n",
      "                                      'in_memory': True,\n",
      "                                      'missing_value_strategy': 'backfill',\n",
      "                                      'norm': None,\n",
      "                                      'padding_value': 0},\n",
      "                         'bag': {   'fill_value': '<UNK>',\n",
      "                                    'lowercase': False,\n",
      "                                    'missing_value_strategy': 'fill_with_const',\n",
      "                                    'most_common': 10000,\n",
      "                                    'tokenizer': 'space'},\n",
      "                         'binary': {   'fill_value': 0,\n",
      "                                       'missing_value_strategy': 'fill_with_const'},\n",
      "                         'category': {   'fill_value': '<UNK>',\n",
      "                                         'lowercase': False,\n",
      "                                         'missing_value_strategy': 'fill_with_const',\n",
      "                                         'most_common': 10000},\n",
      "                         'date': {   'datetime_format': None,\n",
      "                                     'fill_value': '',\n",
      "                                     'missing_value_strategy': 'fill_with_const'},\n",
      "                         'force_split': False,\n",
      "                         'h3': {   'fill_value': 576495936675512319,\n",
      "                                   'missing_value_strategy': 'fill_with_const'},\n",
      "                         'image': {   'in_memory': True,\n",
      "                                      'missing_value_strategy': 'backfill',\n",
      "                                      'num_processes': 1,\n",
      "                                      'resize_method': 'interpolate',\n",
      "                                      'scaling': 'pixel_normalization'},\n",
      "                         'numerical': {   'fill_value': 0,\n",
      "                                          'missing_value_strategy': 'fill_with_const',\n",
      "                                          'normalization': None},\n",
      "                         'sequence': {   'fill_value': '<UNK>',\n",
      "                                         'lowercase': False,\n",
      "                                         'missing_value_strategy': 'fill_with_const',\n",
      "                                         'most_common': 20000,\n",
      "                                         'padding': 'right',\n",
      "                                         'padding_symbol': '<PAD>',\n",
      "                                         'sequence_length_limit': 256,\n",
      "                                         'tokenizer': 'space',\n",
      "                                         'unknown_symbol': '<UNK>',\n",
      "                                         'vocab_file': None},\n",
      "                         'set': {   'fill_value': '<UNK>',\n",
      "                                    'lowercase': False,\n",
      "                                    'missing_value_strategy': 'fill_with_const',\n",
      "                                    'most_common': 10000,\n",
      "                                    'tokenizer': 'space'},\n",
      "                         'split_probabilities': (0.7, 0.1, 0.2),\n",
      "                         'stratify': None,\n",
      "                         'text': {   'char_most_common': 70,\n",
      "                                     'char_sequence_length_limit': 1024,\n",
      "                                     'char_tokenizer': 'characters',\n",
      "                                     'char_vocab_file': None,\n",
      "                                     'fill_value': '<UNK>',\n",
      "                                     'lowercase': True,\n",
      "                                     'missing_value_strategy': 'fill_with_const',\n",
      "                                     'padding': 'right',\n",
      "                                     'padding_symbol': '<PAD>',\n",
      "                                     'pretrained_model_name_or_path': None,\n",
      "                                     'unknown_symbol': '<UNK>',\n",
      "                                     'word_most_common': 20000,\n",
      "                                     'word_sequence_length_limit': 256,\n",
      "                                     'word_tokenizer': 'space_punct',\n",
      "                                     'word_vocab_file': None},\n",
      "                         'timeseries': {   'fill_value': '',\n",
      "                                           'missing_value_strategy': 'fill_with_const',\n",
      "                                           'padding': 'right',\n",
      "                                           'padding_value': 0,\n",
      "                                           'timeseries_length_limit': 256,\n",
      "                                           'tokenizer': 'space'},\n",
      "                         'vector': {   'fill_value': '',\n",
      "                                       'missing_value_strategy': 'fill_with_const'}},\n",
      "    'training': {   'batch_size': 128,\n",
      "                    'bucketing_field': None,\n",
      "                    'decay': False,\n",
      "                    'decay_rate': 0.96,\n",
      "                    'decay_steps': 10000,\n",
      "                    'early_stop': 5,\n",
      "                    'epochs': 100,\n",
      "                    'eval_batch_size': 0,\n",
      "                    'gradient_clipping': None,\n",
      "                    'increase_batch_size_on_plateau': 0,\n",
      "                    'increase_batch_size_on_plateau_max': 512,\n",
      "                    'increase_batch_size_on_plateau_patience': 5,\n",
      "                    'increase_batch_size_on_plateau_rate': 2,\n",
      "                    'learning_rate': 0.001,\n",
      "                    'learning_rate_warmup_epochs': 1,\n",
      "                    'optimizer': {   'beta_1': 0.9,\n",
      "                                     'beta_2': 0.999,\n",
      "                                     'epsilon': 1e-08,\n",
      "                                     'type': 'adam'},\n",
      "                    'reduce_learning_rate_on_plateau': 0,\n",
      "                    'reduce_learning_rate_on_plateau_patience': 5,\n",
      "                    'reduce_learning_rate_on_plateau_rate': 0.5,\n",
      "                    'regularization_lambda': 0,\n",
      "                    'regularizer': 'l2',\n",
      "                    'staircase': False,\n",
      "                    'validation_field': 'combined',\n",
      "                    'validation_metric': 'loss'}}\n",
      "tf_version: '2.3.1'\n",
      "\n",
      "\n",
      "Using full raw csv, no hdf5 and json file with the same name have been found\n",
      "Building dataset (it may take a while)\n",
      "Writing preprocessed dataset cache\n",
      "Writing train set metadata\n",
      "Training set: 105613\n",
      "Validation set: 15071\n",
      "Test set: 30246\n",
      "2020-12-17 02:42:31.019566: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-17 02:42:31.044470: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\n",
      "2020-12-17 02:42:31.044733: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b36a9d8cd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-17 02:42:31.044758: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-12-17 02:42:31.163521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-12-17 02:42:31.164457: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b36cc910f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-17 02:42:31.164479: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2020-12-17 02:42:31.165438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-12-17 02:42:31.166247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2020-12-17 02:42:31.166311: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-12-17 02:42:31.166337: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2020-12-17 02:42:31.166352: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2020-12-17 02:42:31.166367: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2020-12-17 02:42:31.166382: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-12-17 02:42:31.166396: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-12-17 02:42:31.166414: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-12-17 02:42:31.166509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-12-17 02:42:31.167372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-12-17 02:42:31.168154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2020-12-17 02:42:31.168222: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-12-17 02:42:31.665321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-12-17 02:42:31.665363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2020-12-17 02:42:31.665378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2020-12-17 02:42:31.665631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-12-17 02:42:31.666556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-12-17 02:42:31.667368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13970 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)\n",
      "\n",
      "╒══════════╕\n",
      "│ TRAINING │\n",
      "╘══════════╛\n",
      "\n",
      "\n",
      "Epoch   1\n",
      "Training:   0%|                                         | 0/826 [00:00<?, ?it/s]2020-12-17 02:42:33.958700: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2020-12-17 02:42:34.589983: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "Training: 100%|███████████████████████████████| 826/826 [00:39<00:00, 21.08it/s]\n",
      "Evaluation train: 100%|███████████████████████| 826/826 [00:10<00:00, 81.74it/s]\n",
      "Evaluation vali : 100%|███████████████████████| 118/118 [00:01<00:00, 80.65it/s]\n",
      "Evaluation test : 100%|███████████████████████| 237/237 [00:02<00:00, 85.50it/s]\n",
      "Took 53.6156s\n",
      "╒══════════╤════════╤═════════╤══════════════════════╤═══════════════════════╤════════╕\n",
      "│ points   │   loss │   error │   mean_squared_error │   mean_absolute_error │     r2 │\n",
      "╞══════════╪════════╪═════════╪══════════════════════╪═══════════════════════╪════════╡\n",
      "│ train    │ 4.1671 │ -0.5434 │               4.1671 │                1.6005 │ 0.5995 │\n",
      "├──────────┼────────┼─────────┼──────────────────────┼───────────────────────┼────────┤\n",
      "│ vali     │ 4.4852 │ -0.5106 │               4.4852 │                1.6694 │ 0.5693 │\n",
      "├──────────┼────────┼─────────┼──────────────────────┼───────────────────────┼────────┤\n",
      "│ test     │ 4.7160 │ -0.5140 │               4.7160 │                1.6733 │ 0.5467 │\n",
      "╘══════════╧════════╧═════════╧══════════════════════╧═══════════════════════╧════════╛\n",
      "╒════════════╤════════╕\n",
      "│ combined   │   loss │\n",
      "╞════════════╪════════╡\n",
      "│ train      │ 4.0748 │\n",
      "├────────────┼────────┤\n",
      "│ vali       │ 4.3814 │\n",
      "├────────────┼────────┤\n",
      "│ test       │ 4.7915 │\n",
      "╘════════════╧════════╛\n",
      "Validation loss on combined improved, model saved\n",
      "\n",
      "\n",
      "Epoch   2\n",
      "Training: 100%|███████████████████████████████| 826/826 [00:33<00:00, 24.69it/s]\n",
      "Evaluation train: 100%|███████████████████████| 826/826 [00:09<00:00, 89.03it/s]\n",
      "Evaluation vali : 100%|███████████████████████| 118/118 [00:01<00:00, 89.80it/s]\n",
      "Evaluation test : 100%|███████████████████████| 237/237 [00:02<00:00, 89.16it/s]\n",
      "Took 46.7454s\n",
      "╒══════════╤════════╤═════════╤══════════════════════╤═══════════════════════╤════════╕\n",
      "│ points   │   loss │   error │   mean_squared_error │   mean_absolute_error │     r2 │\n",
      "╞══════════╪════════╪═════════╪══════════════════════╪═══════════════════════╪════════╡\n",
      "│ train    │ 4.8052 │ -1.6497 │               4.8052 │                1.8455 │ 0.5370 │\n",
      "├──────────┼────────┼─────────┼──────────────────────┼───────────────────────┼────────┤\n",
      "│ vali     │ 5.5077 │ -1.6242 │               5.5077 │                1.9339 │ 0.4714 │\n",
      "├──────────┼────────┼─────────┼──────────────────────┼───────────────────────┼────────┤\n",
      "│ test     │ 5.6425 │ -1.6170 │               5.6425 │                1.9368 │ 0.4575 │\n",
      "╘══════════╧════════╧═════════╧══════════════════════╧═══════════════════════╧════════╛\n",
      "╒════════════╤════════╕\n",
      "│ combined   │   loss │\n",
      "╞════════════╪════════╡\n",
      "│ train      │ 4.5979 │\n",
      "├────────────┼────────┤\n",
      "│ vali       │ 5.2478 │\n",
      "├────────────┼────────┤\n",
      "│ test       │ 5.4010 │\n",
      "╘════════════╧════════╛\n",
      "Last improvement of combined validation loss happened 1 epoch ago\n",
      "\n",
      "\n",
      "Epoch   3\n",
      "Training: 100%|███████████████████████████████| 826/826 [00:33<00:00, 24.66it/s]\n",
      "Evaluation train: 100%|███████████████████████| 826/826 [00:09<00:00, 88.26it/s]\n",
      "Evaluation vali : 100%|███████████████████████| 118/118 [00:01<00:00, 89.01it/s]\n",
      "Evaluation test : 100%|███████████████████████| 237/237 [00:02<00:00, 88.21it/s]\n",
      "Took 46.9142s\n",
      "╒══════════╤════════╤═════════╤══════════════════════╤═══════════════════════╤════════╕\n",
      "│ points   │   loss │   error │   mean_squared_error │   mean_absolute_error │     r2 │\n",
      "╞══════════╪════════╪═════════╪══════════════════════╪═══════════════════════╪════════╡\n",
      "│ train    │ 5.2466 │ -1.8672 │               5.2466 │                1.9757 │ 0.4937 │\n",
      "├──────────┼────────┼─────────┼──────────────────────┼───────────────────────┼────────┤\n",
      "│ vali     │ 6.1330 │ -1.8450 │               6.1330 │                2.0709 │ 0.4113 │\n",
      "├──────────┼────────┼─────────┼──────────────────────┼───────────────────────┼────────┤\n",
      "│ test     │ 6.2134 │ -1.8340 │               6.2134 │                2.0724 │ 0.4028 │\n",
      "╘══════════╧════════╧═════════╧══════════════════════╧═══════════════════════╧════════╛\n",
      "╒════════════╤════════╕\n",
      "│ combined   │   loss │\n",
      "╞════════════╪════════╡\n",
      "│ train      │ 5.0485 │\n",
      "├────────────┼────────┤\n",
      "│ vali       │ 5.8747 │\n",
      "├────────────┼────────┤\n",
      "│ test       │ 5.9262 │\n",
      "╘════════════╧════════╛\n",
      "Last improvement of combined validation loss happened 2 epochs ago\n",
      "\n",
      "\n",
      "Epoch   4\n",
      "Training: 100%|███████████████████████████████| 826/826 [00:33<00:00, 24.60it/s]\n",
      "Evaluation train: 100%|███████████████████████| 826/826 [00:09<00:00, 87.39it/s]\n",
      "Evaluation vali : 100%|███████████████████████| 118/118 [00:01<00:00, 87.84it/s]\n",
      "Evaluation test : 100%|███████████████████████| 237/237 [00:02<00:00, 87.57it/s]\n",
      "Took 47.1240s\n",
      "╒══════════╤════════╤═════════╤══════════════════════╤═══════════════════════╤════════╕\n",
      "│ points   │   loss │   error │   mean_squared_error │   mean_absolute_error │     r2 │\n",
      "╞══════════╪════════╪═════════╪══════════════════════╪═══════════════════════╪════════╡\n",
      "│ train    │ 4.7314 │  1.7785 │               4.7314 │                1.8562 │ 0.5445 │\n",
      "├──────────┼────────┼─────────┼──────────────────────┼───────────────────────┼────────┤\n",
      "│ vali     │ 5.8434 │  1.7957 │               5.8434 │                1.9822 │ 0.4387 │\n",
      "├──────────┼────────┼─────────┼──────────────────────┼───────────────────────┼────────┤\n",
      "│ test     │ 5.9637 │  1.8016 │               5.9637 │                1.9877 │ 0.4258 │\n",
      "╘══════════╧════════╧═════════╧══════════════════════╧═══════════════════════╧════════╛\n",
      "╒════════════╤════════╕\n",
      "│ combined   │   loss │\n",
      "╞════════════╪════════╡\n",
      "│ train      │ 5.1044 │\n",
      "├────────────┼────────┤\n",
      "│ vali       │ 6.4458 │\n",
      "├────────────┼────────┤\n",
      "│ test       │ 6.5146 │\n",
      "╘════════════╧════════╛\n",
      "Last improvement of combined validation loss happened 3 epochs ago\n",
      "\n",
      "\n",
      "Epoch   5\n",
      "Training: 100%|███████████████████████████████| 826/826 [00:34<00:00, 24.23it/s]\n",
      "Evaluation train: 100%|███████████████████████| 826/826 [00:09<00:00, 85.89it/s]\n",
      "Evaluation vali : 100%|███████████████████████| 118/118 [00:01<00:00, 86.54it/s]\n",
      "Evaluation test : 100%|███████████████████████| 237/237 [00:02<00:00, 85.84it/s]\n",
      "Took 47.8830s\n",
      "╒══════════╤════════╤═════════╤══════════════════════╤═══════════════════════╤════════╕\n",
      "│ points   │   loss │   error │   mean_squared_error │   mean_absolute_error │     r2 │\n",
      "╞══════════╪════════╪═════════╪══════════════════════╪═══════════════════════╪════════╡\n",
      "│ train    │ 1.4962 │  0.4306 │               1.4962 │                0.9540 │ 0.8546 │\n",
      "├──────────┼────────┼─────────┼──────────────────────┼───────────────────────┼────────┤\n",
      "│ vali     │ 2.6556 │  0.4585 │               2.6556 │                1.2236 │ 0.7446 │\n",
      "├──────────┼────────┼─────────┼──────────────────────┼───────────────────────┼────────┤\n",
      "│ test     │ 2.7612 │  0.4532 │               2.7612 │                1.2331 │ 0.7345 │\n",
      "╘══════════╧════════╧═════════╧══════════════════════╧═══════════════════════╧════════╛\n",
      "╒════════════╤════════╕\n",
      "│ combined   │   loss │\n",
      "╞════════════╪════════╡\n",
      "│ train      │ 1.5893 │\n",
      "├────────────┼────────┤\n",
      "│ vali       │ 2.8813 │\n",
      "├────────────┼────────┤\n",
      "│ test       │ 2.9701 │\n",
      "╘════════════╧════════╛\n",
      "Validation loss on combined improved, model saved\n",
      "\n",
      "\n",
      "Epoch   6\n",
      "Training: 100%|███████████████████████████████| 826/826 [00:34<00:00, 24.04it/s]\n",
      "Evaluation train: 100%|███████████████████████| 826/826 [00:09<00:00, 87.73it/s]\n",
      "Evaluation vali : 100%|███████████████████████| 118/118 [00:01<00:00, 88.44it/s]\n",
      "Evaluation test : 100%|███████████████████████| 237/237 [00:02<00:00, 88.04it/s]\n",
      "Took 47.8505s\n",
      "╒══════════╤════════╤═════════╤══════════════════════╤═══════════════════════╤════════╕\n",
      "│ points   │   loss │   error │   mean_squared_error │   mean_absolute_error │     r2 │\n",
      "╞══════════╪════════╪═════════╪══════════════════════╪═══════════════════════╪════════╡\n",
      "│ train    │ 1.7846 │  0.7527 │               1.7846 │                1.0551 │ 0.8290 │\n",
      "├──────────┼────────┼─────────┼──────────────────────┼───────────────────────┼────────┤\n",
      "│ vali     │ 2.9709 │  0.7583 │               2.9709 │                1.3064 │ 0.7145 │\n",
      "├──────────┼────────┼─────────┼──────────────────────┼───────────────────────┼────────┤\n",
      "│ test     │ 3.1156 │  0.7756 │               3.1156 │                1.3237 │ 0.7003 │\n",
      "╘══════════╧════════╧═════════╧══════════════════════╧═══════════════════════╧════════╛\n",
      "╒════════════╤════════╕\n",
      "│ combined   │   loss │\n",
      "╞════════════╪════════╡\n",
      "│ train      │ 1.9014 │\n",
      "├────────────┼────────┤\n",
      "│ vali       │ 3.2736 │\n",
      "├────────────┼────────┤\n",
      "│ test       │ 3.3892 │\n",
      "╘════════════╧════════╛\n",
      "Last improvement of combined validation loss happened 1 epoch ago\n",
      "\n",
      "\n",
      "Epoch   7\n",
      "Training: 100%|███████████████████████████████| 826/826 [00:33<00:00, 24.65it/s]\n",
      "Evaluation train: 100%|███████████████████████| 826/826 [00:09<00:00, 88.83it/s]\n",
      "Evaluation vali : 100%|███████████████████████| 118/118 [00:01<00:00, 89.56it/s]\n",
      "Evaluation test : 100%|███████████████████████| 237/237 [00:02<00:00, 89.29it/s]\n",
      "Took 46.8175s\n",
      "╒══════════╤════════╤═════════╤══════════════════════╤═══════════════════════╤════════╕\n",
      "│ points   │   loss │   error │   mean_squared_error │   mean_absolute_error │     r2 │\n",
      "╞══════════╪════════╪═════════╪══════════════════════╪═══════════════════════╪════════╡\n",
      "│ train    │ 6.9263 │ -2.3994 │               6.9263 │                2.4152 │ 0.3315 │\n",
      "├──────────┼────────┼─────────┼──────────────────────┼───────────────────────┼────────┤\n",
      "│ vali     │ 8.0875 │ -2.3759 │               8.0875 │                2.4843 │ 0.2240 │\n",
      "├──────────┼────────┼─────────┼──────────────────────┼───────────────────────┼────────┤\n",
      "│ test     │ 8.1908 │ -2.3673 │               8.1908 │                2.4876 │ 0.2128 │\n",
      "╘══════════╧════════╧═════════╧══════════════════════╧═══════════════════════╧════════╛\n",
      "╒════════════╤════════╕\n",
      "│ combined   │   loss │\n",
      "╞════════════╪════════╡\n",
      "│ train      │ 6.8776 │\n",
      "├────────────┼────────┤\n",
      "│ vali       │ 7.9009 │\n",
      "├────────────┼────────┤\n",
      "│ test       │ 7.9955 │\n",
      "╘════════════╧════════╛\n",
      "Last improvement of combined validation loss happened 2 epochs ago\n",
      "\n",
      "\n",
      "Epoch   8\n",
      "Training: 100%|███████████████████████████████| 826/826 [00:33<00:00, 24.67it/s]\n",
      "Evaluation train: 100%|███████████████████████| 826/826 [00:09<00:00, 88.69it/s]\n",
      "Evaluation vali : 100%|███████████████████████| 118/118 [00:01<00:00, 89.29it/s]\n",
      "Evaluation test : 100%|███████████████████████| 237/237 [00:02<00:00, 88.95it/s]\n",
      "Took 46.8208s\n",
      "╒══════════╤════════╤═════════╤══════════════════════╤═══════════════════════╤════════╕\n",
      "│ points   │   loss │   error │   mean_squared_error │   mean_absolute_error │     r2 │\n",
      "╞══════════╪════════╪═════════╪══════════════════════╪═══════════════════════╪════════╡\n",
      "│ train    │ 1.3883 │  0.6949 │               1.3883 │                0.9324 │ 0.8666 │\n",
      "├──────────┼────────┼─────────┼──────────────────────┼───────────────────────┼────────┤\n",
      "│ vali     │ 2.7185 │  0.7076 │               2.7185 │                1.2361 │ 0.7386 │\n",
      "├──────────┼────────┼─────────┼──────────────────────┼───────────────────────┼────────┤\n",
      "│ test     │ 2.8627 │  0.7193 │               2.8627 │                1.2484 │ 0.7244 │\n",
      "╘══════════╧════════╧═════════╧══════════════════════╧═══════════════════════╧════════╛\n",
      "╒════════════╤════════╕\n",
      "│ combined   │   loss │\n",
      "╞════════════╪════════╡\n",
      "│ train      │ 1.4781 │\n",
      "├────────────┼────────┤\n",
      "│ vali       │ 3.0024 │\n",
      "├────────────┼────────┤\n",
      "│ test       │ 3.1833 │\n",
      "╘════════════╧════════╛\n",
      "Last improvement of combined validation loss happened 3 epochs ago\n",
      "\n",
      "\n",
      "Epoch   9\n",
      "Training: 100%|███████████████████████████████| 826/826 [00:33<00:00, 24.66it/s]\n",
      "Evaluation train: 100%|███████████████████████| 826/826 [00:09<00:00, 88.25it/s]\n",
      "Evaluation vali : 100%|███████████████████████| 118/118 [00:01<00:00, 88.92it/s]\n",
      "Evaluation test : 100%|███████████████████████| 237/237 [00:02<00:00, 88.59it/s]\n",
      "Took 46.9076s\n",
      "╒══════════╤════════╤═════════╤══════════════════════╤═══════════════════════╤════════╕\n",
      "│ points   │   loss │   error │   mean_squared_error │   mean_absolute_error │     r2 │\n",
      "╞══════════╪════════╪═════════╪══════════════════════╪═══════════════════════╪════════╡\n",
      "│ train    │ 6.4188 │  2.3853 │               6.4188 │                2.3884 │ 0.3816 │\n",
      "├──────────┼────────┼─────────┼──────────────────────┼───────────────────────┼────────┤\n",
      "│ vali     │ 7.8598 │  2.4026 │               7.8598 │                2.4728 │ 0.2442 │\n",
      "├──────────┼────────┼─────────┼──────────────────────┼───────────────────────┼────────┤\n",
      "│ test     │ 8.0154 │  2.4099 │               8.0154 │                2.4775 │ 0.2276 │\n",
      "╘══════════╧════════╧═════════╧══════════════════════╧═══════════════════════╧════════╛\n",
      "╒════════════╤════════╕\n",
      "│ combined   │   loss │\n",
      "╞════════════╪════════╡\n",
      "│ train      │ 6.6186 │\n",
      "├────────────┼────────┤\n",
      "│ vali       │ 8.4477 │\n",
      "├────────────┼────────┤\n",
      "│ test       │ 8.6668 │\n",
      "╘════════════╧════════╛\n",
      "Last improvement of combined validation loss happened 4 epochs ago\n",
      "\n",
      "\n",
      "Epoch  10\n",
      "Training: 100%|███████████████████████████████| 826/826 [00:33<00:00, 24.62it/s]\n",
      "Evaluation train: 100%|███████████████████████| 826/826 [00:09<00:00, 87.75it/s]\n",
      "Evaluation vali : 100%|███████████████████████| 118/118 [00:01<00:00, 88.30it/s]\n",
      "Evaluation test : 100%|███████████████████████| 237/237 [00:02<00:00, 87.90it/s]\n",
      "Took 47.3776s\n",
      "╒══════════╤════════╤═════════╤══════════════════════╤═══════════════════════╤════════╕\n",
      "│ points   │   loss │   error │   mean_squared_error │   mean_absolute_error │     r2 │\n",
      "╞══════════╪════════╪═════════╪══════════════════════╪═══════════════════════╪════════╡\n",
      "│ train    │ 2.8606 │ -1.3861 │               2.8606 │                1.4533 │ 0.7230 │\n",
      "├──────────┼────────┼─────────┼──────────────────────┼───────────────────────┼────────┤\n",
      "│ vali     │ 4.2075 │ -1.3690 │               4.2075 │                1.6657 │ 0.5957 │\n",
      "├──────────┼────────┼─────────┼──────────────────────┼───────────────────────┼────────┤\n",
      "│ test     │ 4.3223 │ -1.3612 │               4.3223 │                1.6750 │ 0.5847 │\n",
      "╘══════════╧════════╧═════════╧══════════════════════╧═══════════════════════╧════════╛\n",
      "╒════════════╤════════╕\n",
      "│ combined   │   loss │\n",
      "╞════════════╪════════╡\n",
      "│ train      │ 2.8279 │\n",
      "├────────────┼────────┤\n",
      "│ vali       │ 4.2417 │\n",
      "├────────────┼────────┤\n",
      "│ test       │ 4.2813 │\n",
      "╘════════════╧════════╛\n",
      "Last improvement of combined validation loss happened 5 epochs ago\n",
      "\n",
      "EARLY STOPPING due to lack of validation improvement, it has been 5 epochs since last validation improvement\n",
      "\n",
      "Best validation model epoch: 5\n",
      "Best validation model loss on validation set combined: 2.88132381439209\n",
      "Best validation model loss on test set combined: 2.9701473712921143\n",
      "\n",
      "Finished: wine_reviews_initial_0_experiment_wine_reviews_initial_0_model\n",
      "Saved to: results/wine_reviews_initial_0_experiment_wine_reviews_initial_0_model\n"
     ]
    }
   ],
   "source": [
    "!ludwig train \\\n",
    "    --experiment_name \"wine_reviews_initial_0_experiment\" \\\n",
    "    --model_name \"wine_reviews_initial_0_model\" \\\n",
    "    --config_file \"../datasets/wine_reviews/cfg.yaml\" \\\n",
    "    --dataset \"/mnt/wine-reviews/winemag-data_first150k.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ludwig writes a lot of files to disk: model checkpoints, training summaries, `tfrecords` files, etcetera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint                         model_weights.index\n",
      "\u001b[0m\u001b[01;34mlogs\u001b[0m/                              \u001b[01;34mtraining_checkpoints\u001b[0m/\n",
      "model_hyperparameters.json         training_progress.json\n",
      "model_weights.data-00000-of-00001  training_set_metadata.json\n"
     ]
    }
   ],
   "source": [
    "%ls /spell/results/wine_reviews_initial_0_experiment_wine_reviews_initial_0_model/model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtraining\u001b[0m/  \u001b[01;34mvalidation\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls /spell/results/wine_reviews_initial_0_experiment_wine_reviews_initial_0_model/model/logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how you would serve this model using a Spell model server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../serve.py\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: this doesn't actually work?\n",
    "# import os; os.symlink(\n",
    "#     \"/usr/local/lib/python3.7/dist-packages/tensorflow/libtensorflow_framework.so.1\",\n",
    "#     \"/usr/local/lib/python3.7/dist-packages/tensorflow/libtensorflow_framework.so.2\"\n",
    "# )\n",
    "from ludwig.api import LudwigModel\n",
    "\n",
    "from spell.serving import BasePredictor\n",
    "\n",
    "class Predictor(BasePredictor):\n",
    "    def __init__(self):\n",
    "        self.ludwig_model = LudwigModel.load(\"/model/\")\n",
    "\n",
    "    def predict(self, payload):\n",
    "        # Ludwig expects input to be in the shape of the original DataFrame.\n",
    "        inp = pd.DataFrame(\n",
    "            {'description': payload['description'], 'points': payload['points']},\n",
    "            index=[0]\n",
    "        )\n",
    "        # Output is a tuple containing a DataFrame entry, which we parse.\n",
    "        result, _ = ludwig_model.predict(inp)\n",
    "        out = {'points': result.points_predictions[0]}\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See also our the blog post, [An introduction to AutoML with Ludwig](https://spell.ml/blog/an-introduction-to-automl-with-ludwig-X_OSWhAAACMA6eYD)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
