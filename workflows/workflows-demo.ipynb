{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# workflows\n",
    "\n",
    "Complex machine learning applications often require multi-stage pipelines (e.g., data loading, transforming, training, testing, iterating). [**Workflows**](https://spell.ml/docs/workflow_overview/) in Spell allow you to manage these pipelines as a sequence of Spell runs, and are a lightweight alternative to tools like [Airflow](https://airflow.apache.org/) and [Luigi](https://github.com/spotify/luigi) for managing your model training pipelines.\n",
    "\n",
    "Workflows can be launched using either the Spell CLI or the Spell Python API. In this tutorial we demonstrate both approaches by example."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## understanding workflows\n",
    "\n",
    "Every workflow consists of one *master run* and one more more *worker runs*. The master run is responsible for control flow: that is, determining which worker runs should get executed when, and why. The worker runs then do all of the work required. For example:\n",
    "\n",
    "![](https://i.imgur.com/W5Ugs0S.png)\n",
    "\n",
    "In this diagram the master run coordinates the sequential execution of three worker runs. More complex workflows may require more complicated control flow.\n",
    "\n",
    "## understanding the workflow script\n",
    "\n",
    "The **workflow script** is what gets executed on the master run: a Python script using the Spell Python API to define worker jobs and the control flow logic surrounding them. Here is a simple example:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%writefile simple.py\n",
    "import spell.client\n",
    "client = spell.client.from_environment()\n",
    "\n",
    "print(client.active_workflow)\n",
    "\n",
    "r1 = client.runs.new(command=\"echo Hello World! > foo.txt\")\n",
    "r1.wait_status(*client.runs.FINAL)\n",
    "r1.refresh()\n",
    "if r1.status != client.runs.COMPLETE:\n",
    "    raise OSError(f\"failed at run {r1.id}\")\n",
    "\n",
    "r2 = client.runs.new(\n",
    "    command=\"cat /mnt/foo.txt\",\n",
    "    attached_resources={f\"runs/{r1.id}/foo.txt\": \"/mnt/foo.txt\"}\n",
    ")\n",
    "r2.wait_status(*client.runs.FINAL)\n",
    "r2.refresh()\n",
    "if r2.status != client.runs.COMPLETE:\n",
    "    raise OSError(f\"failed at run {r2.id}\")\n",
    "\n",
    "print(\"Finished workflow!\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's walk through this script step-by-step:\n",
    "\n",
    "```python\n",
    "import spell.client\n",
    "client = spell.client.from_environment()\n",
    "```\n",
    "\n",
    "This initializes the client object. If you are not familiar with our Python API, check out the [Python API Reference](http://spell.run/docs/python) to learn more.\n",
    "\n",
    "\n",
    "```python\n",
    "print(client.active_workflow)\n",
    "```\n",
    "\n",
    "You can use this variable to determine which workflow the script is currently executing in. In the case that this script is not being run from inside of a workflow this will be set to `None`.\n",
    "\n",
    "```python\n",
    "r1 = client.runs.new(command=\"echo 'Hello World!' > foo.txt\")\n",
    "```\n",
    "\n",
    "This next block of code executes a new run, one which creates a file containing `Hello World!` on disk. [This file automatically gets saved to SpellFS.](https://spell.ml/docs/run_overview/#saving-resources)\n",
    "\n",
    "```python\n",
    "r1.wait_status(*client.runs.FINAL)\n",
    "r1.refresh()\n",
    "if r1.status != client.runs.COMPLETE:\n",
    "    raise OSError(f\"failed at run {r.id}\")\n",
    "```\n",
    "\n",
    "We can only proceed to the next stage of the workflow when the first stage completes successfully. This next bit of code is a control flow block that achieves this.\n",
    "\n",
    "Every run transitions through a sequence of states as part of its execution: `machine_requested`, `running`, `pushing`, and so on. Runs eventually transition to a so-called **final state**: the state that the run is assigned at the end of its execution. There are four different possible final states, the most important of which is `COMPLETE`. A run which terminates in the `COMPLETE` state is one which has successfully run all of its code and pushed all of its outputs to SpellFS.\n",
    "\n",
    "This `wait_status` methods blocks execution until the run API reports that the run has reached a final state. We then `refresh` the information on the run object (this has to be done manually because it requires a network roundtrip) and check if the `r.status` field reports that the run is `COMPLETE`. We only proceed with the rest of the script if it is&mdash;if it is not, e.g. if the run reached a failing final state (`FAILED`, `STOPPED`, or `INTERRUPTED`), we raise an error instead.\n",
    "\n",
    "```python\n",
    "r2 = client.runs.new(\n",
    "    command=\"cat /mnt/foo.txt\",\n",
    "    attached_resources={f\"runs/{r1.id}/foo.txt\": \"/mnt/foo.txt\"}\n",
    ")\n",
    "r2.wait_status(*client.runs.FINAL)\n",
    "r2.refresh()\n",
    "if r2.status != client.runs.COMPLETE:\n",
    "    raise OSError(f\"failed at run {r.id}\")\n",
    "```\n",
    "\n",
    "The next code block creates another Spell run. This time instead of writing `Hello World!` to disk, we mount the `foo.txt` file we created in `r1` into the run. We then `cat` it (print it out to `stdout`), which will cause it to show up in the run logs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## executing the workflow script\n",
    "\n",
    "You can execute the workflow script using the Spell CLI:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "!spell workflow \"python simple.py\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[0mâœ¨ Preparing uncommitted changesâ€¦\n",
      "\u001b[0mEnumerating objects: 9, done.\n",
      "Counting objects: 100% (9/9), done.\n",
      "Delta compression using up to 12 threads\n",
      "Compressing objects: 100% (5/5), done.\n",
      "Writing objects: 100% (5/5), 649 bytes | 649.00 KiB/s, done.\n",
      "Total 5 (delta 4), reused 0 (delta 0)\n",
      "To git.spell.run:aleksey/e6cee8710721a8ef6f3d2924713ac7d351c972ca.git\n",
      " * [new branch]      HEAD -> br_9beb42bead69bba7ca10038c6207ac35601c371b\n",
      "ðŸ’« Casting workflow #14â€¦\n",
      "\u001b[0mâœ¨ Following workflow at run 350.\n",
      "\u001b[0mâœ¨ Stop viewing logs with ^C\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mâœ¨ Buildingâ€¦ donecode[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0mâœ¨ \u001b[0mRun is running\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mâœ¨ Machine_Requestedâ€¦ done-- waiting for a CPU machine..[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mâœ¨ Savingâ€¦ done\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mâœ¨ Pushingâ€¦ done\n",
      "\u001b[0mðŸŽ‰ \u001b[0mTotal run time: 36.630201s\n",
      "\u001b[0mðŸŽ‰ \u001b[0mRun 350 complete\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m\u001b[0m"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can verify that this workflow executed successfully by checking the run logs of the last worker run:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "!spell logs 352"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mâœ¨ Machine_Requestedâ€¦ done\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mâœ¨ Buildingâ€¦ done\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mâœ¨ Mountingâ€¦ done\n",
      "\u001b[0m\u001b[0mâœ¨ \u001b[0mRun is running\n",
      "\u001b[0mHello World!\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mâœ¨ Savingâ€¦ done\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mâœ¨ Pushingâ€¦ done\n",
      "\u001b[0mðŸŽ‰ \u001b[0mTotal run time: 11.525986s\n",
      "\u001b[0mðŸŽ‰ \u001b[0mRun 352 complete\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m\u001b[0m"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## a more complex example\n",
    "\n",
    "As with any run, the code environment in a worker run can be initialized from a GitHub repository using the `--github-url` flag.\n",
    "\n",
    "However, with more complex pipelines it is sometimes useful to make the exact model code used a runtime variable. To support this use case, the Python API additionally supports initializing the code environment from a local `git` repository inside of the master run using the `--repo` flag.\n",
    "\n",
    "The following example demonstrates how this feature works. This workflow downloads a CIFAR10 dataset in one run, and backs that data up to disk. In a second run, it mounts the data downloaded in the first run to disk and trains a model on it.\n",
    "\n",
    "Note the use of the `commit_label` flag on the `run` command; this tells the run to initialize the code environment using the repository with the label `char-rnn`. It is the responsibility of the user to set this value accordingly."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "%%writefile workflow.py\n",
    "import spell.client\n",
    "\n",
    "client = spell.client.from_environment()\n",
    "\n",
    "\n",
    "# Helper function. Throws a ValueError if the run failed.\n",
    "def raise_if_failed(run):\n",
    "    if run.status in [\n",
    "        client.runs.FAILED,\n",
    "        client.runs.BUILD_FAILED,\n",
    "        client.runs.MOUNT_FAILED,\n",
    "    ]:\n",
    "        raise ValueError(f\"Run #{run.id} failed with status `{run.status}`.\")\n",
    "    if run.user_exit_code != 0:\n",
    "        raise ValueError(\n",
    "            f\"Run #{run.id} finished with nonzero exit code \" f\"{run.user_exit_code}.\"\n",
    "        )\n",
    "\n",
    "\n",
    "# The first run downloads the training dataset\n",
    "cmd = \"\"\"\n",
    "import torchvision\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "torchvision.datasets.CIFAR10(\"/spell/cifar10/\", train=True, transform=transform_train, download=True)\n",
    "\"\"\"\n",
    "r1 = client.runs.new(command=f\"python -c '{cmd}'\")\n",
    "print(f\"Waiting for run {r1.id} to complete\")\n",
    "r1.wait_status(*client.runs.FINAL)\n",
    "r1.refresh()\n",
    "raise_if_failed(r1)\n",
    "\n",
    "# The second run trains a model on this dataset\n",
    "r2 = client.runs.new(\n",
    "    machine_type=\"t4\",\n",
    "    command=\"python models/train_basic.py\",\n",
    "    attached_resources={f\"runs/{r1.id}/cifar10\": \"/mnt/cifar10/\"},\n",
    "    commit_label=\"cnn-cifar10\",\n",
    ")\n",
    "print(f\"Waiting for run {r2.id} to complete\")\n",
    "r2.wait_status(*client.runs.FINAL)\n",
    "r2.refresh()\n",
    "raise_if_failed(r2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting workflow.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To run this workflow we will need the following model code:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!git clone https://github.com/spellml/cnn-cifar10.git"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'cnn-cifar10'...\n",
      "remote: Enumerating objects: 159, done.\u001b[K\n",
      "remote: Counting objects: 100% (159/159), done.\u001b[K\n",
      "remote: Compressing objects: 100% (103/103), done.\u001b[K\n",
      "remote: Total 159 (delta 69), reused 126 (delta 39), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (159/159), 544.17 KiB | 1.81 MiB/s, done.\n",
      "Resolving deltas: 100% (69/69), done.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, when we execute this workflow, we parameterize the repo label using the `--repo` flag:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "!spell workflow create \\\n",
    "    --repo cnn-cifar10=cnn-cifar10 \\\n",
    "    \"python workflow.py\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "See also the `with-metrics` directory for another example."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('spell-demo-env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "interpreter": {
   "hash": "a6f85a3ca3d09a94e97867233bb47ae629d35613bc71410f245e77f41de4514f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}