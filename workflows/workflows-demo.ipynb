{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# workflows\n",
    "\n",
    "Complex machine learning applications often require multi-stage pipelines (e.g., data loading, transforming, training, testing, iterating). **Workflows** in Spell allow you to manage these pipelines as a sequence of Spell runs, and are a lightweight alternative to tools like [Airflow](https://airflow.apache.org/) and [Luigi](https://github.com/spotify/luigi) for managing your model training pipelines.\n",
    "\n",
    "Workflows can be launched using either the Spell CLI or the Spell Python API. In this tutorial we demonstrate both approaches by example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## understanding workflows\n",
    "\n",
    "Every workflow consists of one *master run* and one more more *worker runs*. The master run is responsible for control flow: that is, determining which worker runs should get executed when, and why. The worker runs then do all of the work required.\n",
    "\n",
    "Our demo workflow consists of three steps:\n",
    "\n",
    "1. downloading the dataset (a Project Gutenberg copy of _War and Peace_) and saving it to disk.\n",
    "2. mounting that text corpus into a run, training the neural network on it, and saving the model to disk.\n",
    "3. mounting the saved model into yet another run, sampling it for an interesting result, and streaming that output to logs.\n",
    "\n",
    "To accomplish this, we will need one one master run and three worker runs, arranged thusly:\n",
    "\n",
    "![](https://i.imgur.com/W5Ugs0S.png)\n",
    "\n",
    "For this simple example we will execute the steps consecutively, conditioning the start of each worker run in the workflow on the success of its predecessor. More complex workflows may require more complicated control flow.\n",
    "\n",
    "While the instance type of the worker runs is configurable, the master run always executes on the basic `cpu` instance type. Try to keep any computationally intensive logic isolated to the workers!\n",
    "\n",
    "## understanding the workflow script\n",
    "\n",
    "In order to execute a workflow, we need to define a workflow script. The **workflow script** is what gets executed on the master run: a Python script using the Spell Python API to define worker jobs and the control flow logic surrounding them.\n",
    "\n",
    "Here is the workflow script that we will be using for this demo. Don't worry if you don't understand all of it right away, we'll walk through it step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile workflow.py\n",
    "import spell.client\n",
    "client = spell.client.from_environment()\n",
    "\n",
    "# create the first run to download the dataset (War and Peace, by Leo Tolstoy)\n",
    "# if desired, replace data_url with url to another plain text file to train on\n",
    "data_url = \"https://www.gutenberg.org/files/2600/2600-0.txt\"\n",
    "r = client.runs.new(\n",
    "    command=\"wget -O input.txt {}\".format(data_url)\n",
    ")\n",
    "print(\"waiting for run {} to complete\".format(r.id))\n",
    "r.wait_status(*client.runs.FINAL)\n",
    "r.refresh()\n",
    "if r.status != client.runs.COMPLETE:\n",
    "    raise OSError(f\"failed at run {r.id}\")\n",
    "\n",
    "# create the second run to train char-RNN on the dataset\n",
    "data_dir = \"/data\"\n",
    "r = client.runs.new(\n",
    "    machine_type=\"V100\",\n",
    "    command=\"python train.py --data_dir={}\".format(data_dir),\n",
    "    attached_resources={\n",
    "        \"runs/{}/input.txt\".format(r.id): \"{}/input.txt\".format(data_dir)\n",
    "    },\n",
    "    commit_label=\"char-rnn\",\n",
    ")\n",
    "print(\"waiting for run {} to complete\".format(r.id))\n",
    "\n",
    "r.wait_status(*client.runs.FINAL)\n",
    "r.refresh()\n",
    "if r.status != client.runs.COMPLETE:\n",
    "    raise OSError(f\"failed at run {r.id}\")\n",
    "\n",
    "# create the third run that samples the model to generate some text\n",
    "r = client.runs.new(\n",
    "    machine_type=\"V100\",\n",
    "    command=\"python sample.py\",\n",
    "    attached_resources={\"runs/{}/save\".format(r.id): \"save\"},\n",
    "    commit_label=\"char-rnn\",\n",
    ")\n",
    "print(\"waiting for run {} to complete\".format(r.id))\n",
    "\n",
    "r.wait_status(*client.runs.FINAL)\n",
    "r.refresh()\n",
    "if r.status != client.runs.COMPLETE:\n",
    "    raise OSError(f\"failed at run {r.id}\")\n",
    "\n",
    "# print the logs from the last run\n",
    "# generated text should be the last log line\n",
    "print(\"Logs from run {}:\".format(r.id))\n",
    "for line in r.logs():\n",
    "    if line.status == client.runs.RUNNING and not line.status_event:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's walk through this script step-by-step.\n",
    "\n",
    "----\n",
    "\n",
    "```python\n",
    "import spell.client\n",
    "client = spell.client.from_environment()\n",
    "```\n",
    "\n",
    "This initializes the client object. If you are not familiar with our Python API, check out the [Python API Reference](http://spell.run/docs/python) to learn more.\n",
    "\n",
    "----\n",
    "\n",
    "```python\n",
    "data_url = \"https://www.gutenberg.org/files/2600/2600-0.txt\"\n",
    "r = client.runs.new(\n",
    "    command=\"wget -O input.txt {}\".format(data_url)\n",
    ")\n",
    "print(\"waiting for run {} to complete\".format(r.id))\n",
    "```\n",
    "\n",
    "These next few lines create a run executing the command `wget -O input.txt \"https://www.gutenberg.org/files/2600/2600-0.txt\"`. This downloads a copy of _War and Peace_ from the URL given using the `wget` command-line tool.\n",
    "\n",
    "----\n",
    "\n",
    "```python\n",
    "r.wait_status(*client.runs.FINAL)\n",
    "r.refresh()\n",
    "if r.status != client.runs.COMPLETE:\n",
    "    raise OSError(f\"failed at run {r.id}\")\n",
    "```\n",
    "\n",
    "We can only proceed to the next stage of the workflow when the first stage completes successfully. This next bit of code is a control flow block that achieves this end.\n",
    "\n",
    "Every run transitions through a sequence of states as part of its execution: `machine_requested`, `running`, `pushing`, and so on. Runs eventually transition to a so-called **final state**: the state that the run is assigned at the end of its execution. There are four different possible final states, the most important of which is `COMPLETE`. A run which terminates in the `COMPLETE` state is one which has successfully run all of its code and pushed all of its outputs to SpellFS.\n",
    "\n",
    "This `wait_status` methods blocks execution until the run API reports that the run has reached a final state. We then `refresh` the information on the run object (this has to be done manually because it requires a network roundtrip) and check if the `r.status` field reports that the run is `COMPLETE`. We only proceed with the rest of the script if it is&mdash;if it is not, e.g. if the run reached a failing final state (`FAILED`, `STOPPED`, or `INTERRUPTED`), we raise an error instead.\n",
    "\n",
    "----\n",
    "\n",
    "```python\n",
    "data_dir = \"/data\"\n",
    "r = client.runs.new(\n",
    "    machine_type=\"K80\",\n",
    "    command=\"python train.py --data_dir={}\".format(data_dir),\n",
    "    attached_resources={\n",
    "        \"runs/{}/input.txt\".format(r.id): \"{}/input.txt\".format(data_dir)\n",
    "    },\n",
    "    commit_label=\"char-rnn\",\n",
    ")\n",
    "```\n",
    "\n",
    "We are once again executing a worker run and blocking executing until it finishes running. This time we are running the [train.py](https://github.com/sherjilozair/char-rnn-tensorflow/blob/master/train.py) script from the `sherjilozair/char-rnn-tensorflow` repo, using the _War and Peace_ text as our corpus.\n",
    "\n",
    "We are careful to mount the data to the correct `data_dir` inside of the new model training run using the `attached_resources` argument. Outputs that get saved to disk during a run are written to SpellFS at run exit time, allowing us to easily reuse the text corpus we downloaded in the previous command in the next one.\n",
    "\n",
    "Note that we are not passing a `--github-url`! This script instead initializes its code environment using the `commit_label` field. If you skip ahead to the `spell workflow` command we used to initialize the workflow, you see that we set `--repo char-rnn=char-rnn-tensorflow/` as a parameter. When the master run sees that a run has been created with the `char-rnn` `commit_label` set, it knows to copy the contents of this directory into the run.\n",
    "\n",
    "Note that this is a copy operation, not a `git clone`: `commit_label` must point to a directory that actually exists inside of the master run.\n",
    "\n",
    "This feature allows you to share code and data artifacts between the master run and its worker runs. If a previous worker run generated some data that the master run then needed to modify as part of its flow, it's convenient to use `repo` and `commit_label` to pass the master's (updated) data to the worker run.\n",
    "\n",
    "If your master run and worker runs don't need to share any code, you can continue to use `--github-url` as usual.\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "```python\n",
    "r.wait_status(*client.runs.FINAL)\n",
    "r.refresh()\n",
    "if r.status != client.runs.COMPLETE:\n",
    "    raise OSError(f\"failed at run {r.id}\")\n",
    "```\n",
    "\n",
    "We've already seen how this works!\n",
    "\n",
    "----\n",
    "\n",
    "Next we create a third and final run that scores the model on the data:\n",
    "\n",
    "```python\n",
    "# create the third run that samples the model to generate some text\n",
    "r = client.runs.new(\n",
    "    machine_type=\"K80\",\n",
    "    command=\"python sample.py\",\n",
    "    attached_resources={\"runs/{}/save\".format(r.id): \"save\"},\n",
    "    commit_label=\"char-rnn\",\n",
    ")\n",
    "print(\"waiting for run {} to complete\".format(r.id))\n",
    "r.wait_status(client.runs.COMPLETE)\n",
    "```\n",
    "\n",
    "This works much the same way to previous run worked.\n",
    "\n",
    "----\n",
    "\n",
    "The `sample.py` script prints its results to `stdout`, so the last thing we do before exiting is printing out the lines from the log:\n",
    "\n",
    "```python\n",
    "print(\"Logs from run {}:\".format(r.id))\n",
    "for line in r.logs():\n",
    "    if line.status == client.runs.RUNNING and not line.status_event:\n",
    "        print(line)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## executing the workflow script\n",
    "\n",
    "Now that we understand this script, it's time to run it.\n",
    "\n",
    "First of all, since we're passing the character-level RNN code into the run using `repo`/`commit_label`, we will want to clone that code to local disk so that it is included in the master run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'char-rnn-tensorflow'...\n",
      "remote: Enumerating objects: 404, done.\u001b[K\n",
      "remote: Total 404 (delta 0), reused 0 (delta 0), pack-reused 404\u001b[K\n",
      "Receiving objects: 100% (404/404), 508.45 KiB | 1.72 MiB/s, done.\n",
      "Resolving deltas: 100% (238/238), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/sherjilozair/char-rnn-tensorflow.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, to actually run this workflow, we execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mâœ¨ Syncing repo char-rnn-tensorflow/.\n",
      "\u001b[0mEverything up-to-date\n",
      "Enumerating objects: 9, done.\n",
      "Counting objects: 100% (9/9), done.\n",
      "Delta compression using up to 12 threads\n",
      "Compressing objects: 100% (5/5), done.\n",
      "Writing objects: 100% (5/5), 770 bytes | 770.00 KiB/s, done.\n",
      "Total 5 (delta 4), reused 0 (delta 0)\n",
      "To git.spell.run:aleksey/e6cee8710721a8ef6f3d2924713ac7d351c972ca.git\n",
      " * [new branch]      HEAD -> br_25a003b88233dda6a67d2e47db041b920965d26d\n",
      "ðŸ’« Casting workflow #9â€¦\n",
      "\u001b[0mâœ¨ Following workflow at run 335.\n",
      "\u001b[0mâœ¨ Stop viewing logs with ^C\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mâœ¨ Machine_Requestedâ€¦ donee into environment[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mâœ¨ Buildingâ€¦ done\n",
      "\u001b[0mâœ¨ \u001b[0mRun is running\n",
      "\u001b[0mwaiting for run 336 to complete\n",
      "\u001b[0mwaiting for run 337 to complete\n",
      "\u001b[0mwaiting for run 338 to complete\n",
      "\u001b[0mLogs from run 338:\n",
      "\u001b[0mWARNING:tensorflow:From /spell/model.py:30: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "\u001b[0mInstructions for updating:\n",
      "\u001b[0mThis class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "\u001b[0mWARNING:tensorflow:From /spell/model.py:36: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "\u001b[0mInstructions for updating:\n",
      "\u001b[0mThis class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "\u001b[0mWARNING:tensorflow:From /spell/model.py:39: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\u001b[0m\n",
      "\u001b[0mWARNING:tensorflow:From /spell/model.py:46: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\u001b[0m\n",
      "\u001b[0mWARNING:tensorflow:From /spell/model.py:47: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\u001b[0m\n",
      "\u001b[0mWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "\u001b[0mInstructions for updating:\n",
      "\u001b[0mCall initializer instance with the dtype argument instead of passing it to the constructor\n",
      "\u001b[0mWARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f1c5bdd9090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f1c5bdd9090>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "\u001b[0mWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "\u001b[0mInstructions for updating:\n",
      "\u001b[0mCall initializer instance with the dtype argument instead of passing it to the constructor\n",
      "\u001b[0mWARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f1cb43dff10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f1cb43dff10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "\u001b[0mWARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f1c5bdcac90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f1c5bdcac90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "\u001b[0mWARNING:tensorflow:From /spell/model.py:86: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\u001b[0m\n",
      "\u001b[0mWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[0mInstructions for updating:\n",
      "\u001b[0mUse tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[0mWARNING:tensorflow:From /spell/model.py:92: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[0mWARNING:tensorflow:From /spell/model.py:98: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\u001b[0m\n",
      "\u001b[0mWARNING:tensorflow:From /spell/model.py:100: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\u001b[0m\n",
      "\u001b[0mWARNING:tensorflow:From sample.py:39: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\u001b[0m\n",
      "\u001b[0m2020-05-05 15:35:50.419686: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "\u001b[0m2020-05-05 15:35:50.442808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[0m2020-05-05 15:35:50.443751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "\u001b[0mname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "\u001b[0mpciBusID: 0000:00:1e.0\n",
      "\u001b[0m2020-05-05 15:35:50.446666: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "\u001b[0m2020-05-05 15:35:50.510096: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "\u001b[0m2020-05-05 15:35:50.539823: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "\u001b[0m2020-05-05 15:35:50.548937: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "\u001b[0m2020-05-05 15:35:50.624807: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "\u001b[0m2020-05-05 15:35:50.668674: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "\u001b[0m2020-05-05 15:35:50.947726: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "\u001b[0m2020-05-05 15:35:50.947912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[0m2020-05-05 15:35:50.949022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[0m2020-05-05 15:35:50.949930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "\u001b[0m2020-05-05 15:35:50.950331: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[0m2020-05-05 15:35:50.978513: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300030000 Hz\n",
      "\u001b[0m2020-05-05 15:35:50.979175: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56035b408e70 executing computations on platform Host. Devices:\n",
      "\u001b[0m2020-05-05 15:35:50.979209: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "\u001b[0m2020-05-05 15:35:51.085518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[0m2020-05-05 15:35:51.086565: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56035bc81660 executing computations on platform CUDA. Devices:\n",
      "\u001b[0m2020-05-05 15:35:51.086593: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
      "\u001b[0m2020-05-05 15:35:51.086806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[0m2020-05-05 15:35:51.087756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "\u001b[0mname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "\u001b[0mpciBusID: 0000:00:1e.0\n",
      "\u001b[0m2020-05-05 15:35:51.087815: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "\u001b[0m2020-05-05 15:35:51.087845: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "\u001b[0m2020-05-05 15:35:51.087872: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "\u001b[0m2020-05-05 15:35:51.087895: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "\u001b[0m2020-05-05 15:35:51.087926: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "\u001b[0m2020-05-05 15:35:51.087964: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "\u001b[0m2020-05-05 15:35:51.088000: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "\u001b[0m2020-05-05 15:35:51.088102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[0m2020-05-05 15:35:51.089081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[0m2020-05-05 15:35:51.090002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "\u001b[0m2020-05-05 15:35:51.091094: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "\u001b[0m2020-05-05 15:35:51.094174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "\u001b[0m2020-05-05 15:35:51.094198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "\u001b[0m2020-05-05 15:35:51.094206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "\u001b[0m2020-05-05 15:35:51.094410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[0m2020-05-05 15:35:51.095496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[0m2020-05-05 15:35:51.096496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15052 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0)\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mâœ¨ Savingâ€¦ done\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0mâœ¨ Pushingâ€¦ done\n",
      "\u001b[0mðŸŽ‰ \u001b[0mTotal run time: 33m46.17705s\n",
      "\u001b[0mðŸŽ‰ \u001b[0mRun 335 complete\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell workflow \\\n",
    "    --repo char-rnn=char-rnn-tensorflow/ \\\n",
    "    \"python workflow.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the run logs in the web console we see the following generated text (your sample will look different):\n",
    "\n",
    "```\n",
    "May 05, 2020, 11:35:55: running:  of Moscupe, who foll and since hoer. We are and still turned\n",
    "May 05, 2020, 11:35:55: running: merely as the corner that argument in lors for so a quality that.\n",
    "May 05, 2020, 11:35:55: running: Welllaration wehe return, raisements of\n",
    "May 05, 2020, 11:35:55: running: such a Frenchmen inspecting for them tallow me with the same correct actions,\n",
    "May 05, 2020, 11:35:55: running: fellows and wellâ€”or watching, in animation, gay others.\n",
    "May 05, 2020, 11:35:55: running: \n",
    "May 05, 2020, 11:35:55: running: \n",
    "May 05, 2020, 11:35:55: running: \n",
    "May 05, 2020, 11:35:55: running: \n",
    "May 05, 2020, 11:35:55: running: \n",
    "May 05, 2020, 11:35:55: running: CHAPTER XVIII\n",
    "May 05, 2020, 11:35:55: running:  Yasova and givein offers, and manâ€”do not restraining the woode, they pause they seemed to many apply as he left cordier in\n",
    "May 05, 2020, 11:35:55: running: which Now did not be week wiplocking France\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that concludes our demo!\n",
    "\n",
    "For even more code samples refer to the `simple` and `video-generation-workflow` folders in this repository."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
