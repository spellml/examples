{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python-quickstart\n",
    "\n",
    "This page is a brisk introduction to Spell's [Python API](https://spell.run/docs/python). The Spell Python library provides programmatic access to the following APIs (click to go to the corresponding section of this guide):\n",
    "\n",
    "* [Runs](#runs)\n",
    "* [Resources](#resources)\n",
    "* [Hyperparameter Searches](#hyperparameter-searches)\n",
    "* [Models](#models)\n",
    "* [Model Servers](#model-servers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run basics\n",
    "\n",
    "First use `spell.client.from_environment` to instantiate the Spell Python client with your credentials.\n",
    "\n",
    "This works inside of a Spell workspace or run automatically (your credentials are included in the run environment).\n",
    "\n",
    "If you are on your local machine, note that you will first need to log in using the `spell login` CLI command. You only need to do this once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spell.client\n",
    "client = spell.client.from_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python equivalent to the `spell run` CLI command is `client.runs.new`. This function contains all of the same parameters (well, mostly) and returns a `Run` object you can use for further interaction with this run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mruns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Create a run.\n",
      "\n",
      "Args:\n",
      "    command (str): the command to run\n",
      "    machine_type (str, optional): the machine type for the run (default: CPU)\n",
      "    project (str, optional): the project to associate this run with (default: None)\n",
      "    workspace_id (int, optional): the workspace ID for code to include in the run (default: None)\n",
      "    commit_hash (str, optional): a specific commit hash in the workspace corresponding to :obj:`workspace_id`\n",
      "        for code to include in the run (default: None)\n",
      "    commit_label (str, optional): a commit label for code to include in the run. Only applicable\n",
      "        if this is a workflow run (i.e., the :py:attr:`~spell.client.SpellClient.active_workflow` of the\n",
      "        client is set or a :obj:`workflow_id` is provided) (default: None). The value must correspond\n",
      "        to one of the commit labels specified upon workflow creation using the ``--repo`` or ``--github-repo``\n",
      "        options. Only applicable if a workspace is specified.\n",
      "    github_url (str, optional): a GitHub URL to a repository for code to include in the run. Not applicable\n",
      "        when :obj:`workspace_id` or :obj:`commit_label` is specified.\n",
      "    github_ref (str, optional): a reference to a commit, branch, or tag in the repository corresponding to\n",
      "        :obj:`github_url` for code to include in the run (default: master)\n",
      "    pip_packages (:obj:`list` of :obj:`str`, optional): pip dependencies (default: None).\n",
      "        For example: ``[\"moviepy\", \"scikit-image\"]``\n",
      "    apt_packages (:obj:`list` of :obj:`str`, optional): apt dependencies (default: None).\n",
      "        For example: ``[\"python-tk\", \"ffmpeg\"]``\n",
      "    requirements_file (str, optional): a path to a requirements file\n",
      "    envvars (:obj:`dict` of :obj:`str` -> :obj:`str`, optional): name to value mapping of\n",
      "        environment variables for the run (default: None).\n",
      "        For example: ``{\"VARIABLE\" : \"VALUE\", \"LANG\" : \"C.UTF-8\"}``\n",
      "    cwd (str, optional): the working directory within the repository in which to execute the command\n",
      "        (default: None). Only applicable if a workspace is specified.\n",
      "    tensorboard_directory(str, optional): the path where tensorboard files will be read from.\n",
      "    distributed(int, optional): execute a distributed run using N machines of the specified machine type.\n",
      "    conda_file (str, optional): the path to a conda specification file or YAML environment file (default: None).\n",
      "    docker_image (str, optional): the name of docker image to use as base (default: None)\n",
      "    framework (str, optional): the framework to use for the run (default: None). For example: ``pytorch``\n",
      "    framework_version (str, optional): the framework version to use for the run (default: None).\n",
      "        For example: ``0.2.0``\n",
      "    attached_resources (:obj:`dict` of :obj:`str` -> :obj:`str`, optional): resource name to\n",
      "        mountpoint mapping of attached resouces for the run (default: None).\n",
      "        For example: ``{\"runs/42\" : \"/mnt/data\"}``\n",
      "    description (str, optional): a description for the run (default: None)\n",
      "    idempotent (bool, optional): use an existing identical run if available in lieu of re-running\n",
      "        (default: false)\n",
      "    workflow_id (int, optional): the id of the workflow to which this run will be associated (default: None).\n",
      "        This argument is unnecessary if the :py:attr:`~spell.client.SpellClient.active_workflow` of\n",
      "        the client is set and this argument will take precedence if they differ.\n",
      "    auto_resume (bool, optional): Enable or disable auto-resume. When left unspecified the default value for\n",
      "        the machine type will be used. NOTE: This is only supported for spot instance machine types. It is not\n",
      "        currently supported on Azure.\n",
      "\n",
      "Returns:\n",
      "    A :py:class:`Run` object.\n",
      "\n",
      "Raises:\n",
      "    :py:class:`~spell.api.exceptions.ClientException`: an error occured.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Desktop/spell/python/spell/client/runs.py\n",
      "\u001b[0;31mType:\u001b[0m      method\n"
     ],
     "name": "stdout"
    }
   ],
   "source": [
    "client.runs.new?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = client.runs.new(command=\"echo Hello World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id=355, status='machine_requested', command='echo Hello World!', creator=User(email='aleksey@spell.run', user_name='aleksey', full_name='Aleksey Bilogur', created_at=datetime.datetime(2020, 2, 12, 23, 28, 32, 771444, tzinfo=tzutc()), updated_at=datetime.datetime(2020, 4, 28, 0, 27, 17, 514510, tzinfo=tzutc()), last_logged_in=datetime.datetime(2020, 4, 28, 0, 27, 17, 390465, tzinfo=tzutc())), gpu='CPU', framework='default', created_at=datetime.datetime(2020, 5, 6, 15, 14, 29, 659725, tzinfo=tzutc()))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these fields is an attribute on the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machine_requested'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important `Run` attributes is the `status`. The `status` field reflects the state the run was in at the time the `Run` object was last generated or refreshed.\n",
    "\n",
    "`client.runs.new` always exits as soon as the run is successfully queued, hence it always returns a `Run` object in the `'machine_requested'` state. To update the `status` field, run `refresh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'complete'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also initialize a `Run` object from an existing run by ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = client.runs.get(355)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### waiting on run completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To wait until the run reaches a certain state, use `wait_status`. For a full list of states that a run can be in refer to [\"Run States\"](https://spell.run/docs/run_overview#advanced-run-states) in the runs documentation. In most cases you will simply want to wait until the run terminates (reaching one of the final states); you can then check for `status == 'complete'` to determine whether or not the run succeeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run succeeded!\n"
     ]
    }
   ],
   "source": [
    "r2 = client.runs.new(command=\"echo Hello World Again!\")\n",
    "r2.wait_status(*client.runs.FINAL)\n",
    "r2.refresh()\n",
    "if r2.status == client.runs.COMPLETE:\n",
    "    print(\"Run succeeded!\")\n",
    "else:\n",
    "    print(\"Run failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting run logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logs associated with a run are available as a sequence of `LogEntry` objects via `logs`. The `LogEntry` object provides the same information that the logs in the web console provide in a more Pythonic way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogEntry(status='machine_requested', log='Run created -- waiting for a CPU machine.', status_event=True, level='info', timestamp='2020-05-06T15:56:07+00:00'),\n",
       " LogEntry(status='building', log='Run is building', status_event=True, level='info', timestamp='2020-05-06T15:56:08+00:00'),\n",
       " LogEntry(status='building', log='Machine acquired -- commencing run', level='info', timestamp='2020-05-06T15:56:08+00:00'),\n",
       " LogEntry(status='building', log='Retrieving cached environment...', timestamp='2020-05-06T15:56:13+00:00'),\n",
       " LogEntry(status='running', log='Run is running', status_event=True, level='info', timestamp='2020-05-06T15:56:19+00:00'),\n",
       " LogEntry(status='running', log='Hello World Again!', timestamp='2020-05-06T15:56:21+00:00'),\n",
       " LogEntry(status='saving', log='Run is saving', status_event=True, level='info', timestamp='2020-05-06T15:56:22+00:00'),\n",
       " LogEntry(status='pushing', log='Run is pushing', status_event=True, level='info', timestamp='2020-05-06T15:56:26+00:00'),\n",
       " LogEntry(status='pushing', log='Saving build environment for future runs', level='info', timestamp='2020-05-06T15:56:26+00:00'),\n",
       " LogEntry(status='complete', log='Total run time: 13.261553s', status_event=True, level='info', timestamp='2020-05-06T15:56:26+00:00'),\n",
       " LogEntry(status='complete', log='Run 356 complete', status_event=True, level='info', timestamp='2020-05-06T15:56:26+00:00'),\n",
       " LogEntry(status='saving', log='Scanning for modified or new files from the run', timestamp='2020-05-06T15:56:23+00:00'),\n",
       " LogEntry(status='saving', log='No modified or new files found', timestamp='2020-05-06T15:56:23+00:00')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(r2.logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get only the log lines corresponding with user output, filter on `status == 'running'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogEntry(status='running', log='Run is running', status_event=True, level='info', timestamp='2020-05-06T15:56:19+00:00'),\n",
       " LogEntry(status='running', log='Hello World Again!', timestamp='2020-05-06T15:56:21+00:00')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[log for log in r2.logs() if log.status == client.runs.RUNNING]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### terminating a run\n",
    "\n",
    "You can `stop` or `kill` a run using the Python client in much the same way you can using the Spell CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'killed'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r3 = client.runs.new(command=\"sleep 1000\")\n",
    "r3.wait_status(client.runs.RUNNING)\n",
    "r3.kill()  # or r3.stop()\n",
    "r3.wait_status(*client.runs.FINAL)\n",
    "r3.refresh()\n",
    "r3.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the difference between `stop` and `kill` refer to [\"Interrupting a run\"](https://spell.run/docs/run_overview#interrupting-a-run) in the Runs documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copying run resources\n",
    "\n",
    "You can copy run resources to local disk using `cp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "r4 = client.runs.new(command=\"echo Hello World > hello_world.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "r4.cp(\"hello_world.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello_world.txt   quickstart.ipynb\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### working with run metrics\n",
    "\n",
    "As the [Metrics](https://spell.run/docs/metrics/) page in the docs explains, you can use the `send_metric` method inside of a run to report model metrics to Spell, then use `run.metrics` to retrieve them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../metrics/basic.py\n",
    "import spell.metrics as metrics\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "# Runs for --steps seconds and sends --steps spell metrics with the key 'value'\n",
    "# and a numeric value starting at --start and incrementing by --stepsize\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--start\", type=float, help=\"Value to start at\")\n",
    "    parser.add_argument(\"--steps\", type=int, help=\"Number of metrics to send\")\n",
    "    parser.add_argument(\"--stepsize\", type=float, help=\"Size of step to take\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    value = args.start\n",
    "    for i in range(args.steps):\n",
    "        print(\"Sending metric {}\".format(value))\n",
    "        metrics.send_metric(\"value\", value) \n",
    "        value += args.stepsize\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "r5 = client.runs.new(\n",
    "    github_url=\"https://github.com/spellrun/examples.git\", \n",
    "    command=\"python metrics/basic.py --start 1 --steps 4 --stepsize 1\",\n",
    ")\n",
    "r5.wait_status(*client.runs.FINAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>index</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-06 18:20:50.544695+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-06 18:20:51.550610+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-06 18:20:52.554921+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-06 18:20:53.559158+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         timestamp  index  value\n",
       "0 2020-05-06 18:20:50.544695+00:00      0      1\n",
       "1 2020-05-06 18:20:51.550610+00:00      1      2\n",
       "2 2020-05-06 18:20:52.554921+00:00      2      3\n",
       "3 2020-05-06 18:20:53.559158+00:00      3      4"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load ../metrics/read.py\n",
    "import pandas as pd\n",
    "import spell.client\n",
    "\n",
    "client = spell.client.from_environment()\n",
    "\n",
    "# replace with the actual run id value\n",
    "RUN_ID = r5.id\n",
    "run = client.runs.get(RUN_ID)\n",
    "\n",
    "# we return the metrics data as a generator\n",
    "metric = run.metrics(\"value\")\n",
    "\n",
    "df = pd.DataFrame(metric, columns=[\"timestamp\", \"index\", \"value\"])\n",
    "df"
   ]
  },
  {
   "source": [
    "### assigning a run to a project\n",
    "\n",
    "You can group your runs (and build dashboards for them) using [project](https://spell.ml/docs/project_overview/). To attach a new run to a project, using the `project` field:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r6 = client.runs.new(\n",
    "    command=\"echo Hello World!\",\n",
    "    project=\"MNIST\"\n",
    ")\n",
    "r6.wait_status(*client.runs.FINAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Project(id=6, name='MNIST', description='Attempts to categorize images of hand drawn digits')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "r6.project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more `run` methods refer to the [run docs](https://spell.ml/docs/runs/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### working with workflows\n",
    "\n",
    "The master run script in a workflow leverages the Python API to do its work. Refer to the `workflows` folder in this repository to learn more.\n",
    "\n",
    "Note that it is not currently possible to launch a new workflow from the Python API.\n",
    "\n",
    "----"
   ]
  },
  {
   "source": [
    "## resources"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "You can interact with Spell resources via the Python API. The resources client has two methods: `ls` for viewing resources (`uploads/` for uploads, `runs/` for runs) and `cp` for downloading them to local disk."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spell.client\n",
    "client = spell.client.from_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[LsLine(path='100MDataset', date='2019-10-21T15:27:33.707682Z'),\n",
       " LsLine(path='cifar10', date='2020-08-11T00:10:35.147822Z'),\n",
       " LsLine(path='coconet-model', date='2020-11-10T18:47:37.711716Z'),\n",
       " LsLine(path='dogs', date='2020-03-11T15:13:02.542201Z'),\n",
       " LsLine(path='examples', date='2019-10-21T15:35:34.379891Z'),\n",
       " LsLine(path='fluent-logger-golang', date='2019-10-21T15:16:45.234666Z'),\n",
       " LsLine(path='guitar_chords', date='2020-03-15T17:22:43.22915Z'),\n",
       " LsLine(path='hptwo', date='2019-10-31T22:37:08.514779Z'),\n",
       " LsLine(path='JSB-Chorales-dataset', date='2020-11-10T17:28:10.325366Z'),\n",
       " LsLine(path='liberty-mutual-group-property-inspection-prediction', date='2020-08-10T23:08:31.005482Z'),\n",
       " LsLine(path='neural-style-imgs', date='2021-03-12T21:40:57.339617Z'),\n",
       " LsLine(path='output', date='2019-10-21T15:26:05.716872Z'),\n",
       " LsLine(path='paint_with_ml', date='2020-09-15T15:38:37.959968Z'),\n",
       " LsLine(path='pytorch-examples', date='2019-10-21T15:54:12.092107Z'),\n",
       " LsLine(path='serving', date='2021-01-26T17:49:38.997669Z'),\n",
       " LsLine(path='sonic-dreams', date='2021-03-15T00:03:49.410083Z'),\n",
       " LsLine(path='video-frames', date='2019-10-18T21:08:48.07663Z'),\n",
       " LsLine(path='waldo', date='2021-03-02T16:41:40.893596Z')]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "list(client.resources.ls(\"uploads/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[LsLine(path='GuaGAN_Bob_Ross_From_ADE20K_Landscapes_No_VAE/'),\n",
       " LsLine(path='latest_net_G.yaml', size=612, date='2020-09-15T15:47:11Z')]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "list(client.resources.ls(\"runs/1011\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting keras_cifar10_trained_model.h5...\n"
     ]
    }
   ],
   "source": [
    "client.resources.cp(\"runs/17/keras/saved_models/\", \"checkpoints/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameter searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To launch a hyperparameter search using the Spell Python library, use one of the three launcher methods (`new_grid_search`, `new_random_search`, and `new_bayesian_search` in the `client.hyper.*` namespace.\n",
    "\n",
    "To learn more about the hyperparameter search feature, refer to our blog post [\"An introduction to hyperparameter search with CIFAR10\"](https://spell.run/blog/an-introduction-to-hyperparameter-search-with-cifar10-Xo8_6BMAACEAkwVs), the hyperparameter search tutorial in the `hyper` folder in this repo, and/or our [hyperparameter search docs](https://spell.run/docs/hyper_searches) page.\n",
    "\n",
    "The following code sample demonstrates this in action. Note that running this code cell launches a large hyperparameter search job, so be prepared for this if you do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spell.api.models import ValueSpec\n",
    "\n",
    "h1 = client.hyper.new_grid_search(\n",
    "    params={\n",
    "        'conv2_filter': ValueSpec([16, 72, 128]),\n",
    "        'dense_layer': ValueSpec([32, 64, 128]),\n",
    "        'dropout_3': ValueSpec([0.2, 0.5])\n",
    "    },\n",
    "    command=\"python hyper/cifar10_cnn.py --epochs 25 --conv2_filter :conv2_filter: --dense_layer :dense_layer: --dropout_3 :dropout_3:\",\n",
    "    machine_type=\"K80\",\n",
    "    github_url=\"https://github.com/spellrun/examples.git\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter search methods accept all of the same parameters that the run creation method (`spell.client.new`) accepts, plus one new one, `params`, specifying the hyperparameter search space.\n",
    "\n",
    "Note also that you will need to provide the run instruction explicitly via the `command` keyword argument.\n",
    "\n",
    "The input to `params` can be a `dict` of `ValueSpec` objects wrapping a list, in the case of `new_grid_search`, or a `dict` or `RangeSpec` objects, in the case of `new_random_search` and `new_bayesian_search`. Here's an example of a random search using `RangeSpec`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spell.api.models import RangeSpec\n",
    "\n",
    "h2 = client.hyper.new_random_search(\n",
    "    params={\n",
    "        'conv2_filter': RangeSpec(16, 128, scaling='linear', type='int'),\n",
    "        'dense_layer': RangeSpec(32, 128, scaling='linear', type='int'),\n",
    "        'dropout_3': RangeSpec(0.2, 0.5)\n",
    "    },\n",
    "    num_runs=12,\n",
    "    command=\"python hyper/cifar10_cnn.py --epochs 25 --conv2_filter :conv2_filter: --dense_layer :dense_layer: --dropout_3 :dropout_3:\",\n",
    "    machine_type=\"K80\",\n",
    "    github_url=\"https://github.com/spellrun/examples.git\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note also the presence of the `num_runs` attribute here; this controls how many jobs will be launched as part of this search. `num_jobs` is a required parameter for random and Bayesian searches only.\n",
    "\n",
    "The individual runs associated with the hyperparameter search job are available via the `runs` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id=397, status='machine_requested', command='python hyper/cifar10_cnn.py --epochs 25 --conv2_filter 111 --dense_layer 53 --dropout_3 0.47596198145023644', creator=User(email='aleksey@spell.run', user_name='aleksey', full_name='Aleksey Bilogur', created_at=datetime.datetime(2020, 2, 12, 23, 28, 32, 771444, tzinfo=tzutc()), updated_at=datetime.datetime(2020, 4, 28, 0, 27, 17, 514510, tzinfo=tzutc()), last_logged_in=datetime.datetime(2020, 4, 28, 0, 27, 17, 390465, tzinfo=tzutc())), gpu='K80', git_commit_hash='c27875680c5de4a18dbff080ae6d97d1eb6bac6a', github_url='https://github.com/spellrun/examples', framework='default', created_at=datetime.datetime(2020, 5, 6, 19, 6, 7, 970882, tzinfo=tzutc()), hyper_params={'conv2_filter': 111, 'dense_layer': 53, 'dropout_3': 0.47596198145023644})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2.runs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with runs, to catch the state of the hyperparameter search object up to latest you need to run `refresh`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2.refresh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To stop or kill the search job, use the `stop` or `kill` methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get metrics from the hyperparameter runs by name using the `metrics_names` and `metrics` methods. The latter will return an iterator over all metrics from the search sorted by run ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_loss', 'val_loss', 'val_acc']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2.metric_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{952: <list_iterator at 0x7fa52c2b3610>,\n",
       " 953: <list_iterator at 0x7fa52d093990>,\n",
       " 954: <list_iterator at 0x7fa52d093690>,\n",
       " 955: <list_iterator at 0x7fa52d093650>,\n",
       " 956: <list_iterator at 0x7fa52d093750>,\n",
       " 957: <list_iterator at 0x7fa52d093fd0>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = h2.metrics('train_loss')\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more hyperparameter search methods refer to the [hyperparameter search docs](https://spell.ml/docs/hyper_searches/).\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## models\n",
    "\n",
    "Models are a way of organizing models you've trained on Spell. They are used by Spell model servers, but can also be exported out of Spell if, for example, you want to use the model you trained locally.\n",
    "\n",
    "To initialize a new model (or a new version of existing model), use the `new` method. Models can be created from either runs or uploads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.models.new(\"cnn-cifar10\", \"runs/951\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `list` to get all of models in your account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = client.models.list()\n",
    "len(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `model` object has a `model_versions` attribute, which contains a list of model versions this model has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelVersion(id=1, formatted_version='v1', creator=User(email='aleksey@spell.ml', user_name='aleksey', full_name='Aleksey Bilogur', created_at=datetime.datetime(2020, 2, 12, 23, 28, 32, 771444, tzinfo=tzutc()), updated_at=datetime.datetime(2021, 3, 28, 17, 13, 31, 38826, tzinfo=tzutc()), is_admin=True, last_logged_in=datetime.datetime(2021, 3, 28, 17, 13, 30, 667623, tzinfo=tzutc())), created_at=datetime.datetime(2021, 4, 22, 18, 48, 26, 792185, tzinfo=tzutc()), resource='runs/951', files=[<spell.api.models.ModelFileSpec object at 0x7fa52d3372d0>])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_model_version = model.model_versions[-1]\n",
    "latest_model_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the contents of the model version to local disc using the `download` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model. This may take some time...\n",
      "Extracting checkpoints/epoch_10.pth...\n",
      "Extracting checkpoints/epoch_15.pth...\n",
      "Extracting checkpoints/epoch_20.pth...\n",
      "Extracting checkpoints/epoch_5.pth...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "latest_model_version.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more model methods refer to the [model docs](https://spell.ml/docs/pythonModels/).\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model servers\n",
    "\n",
    "Model servers are models served as an API endpoint on a Kubernetes cluster running on Spell. You can create a new one using `serve`, list existing ones using `list`, and get an existing one using `get`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentrypoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgithub_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Create a new model server using a model.\n",
       "\n",
       "Parameters:\n",
       "    model (str): Targeted model, should be in ``MODEL:VERSION`` format\n",
       "    entrypoint (str): Path to the file to be used as the model server entrypoint, e.g.\n",
       "        ``serve.py`` or similar.\n",
       "    github_url (str): a GitHub URL to a repository for code to include in the server.\n",
       "    github_ref (str, optional): a reference to a commit, branch, or tag in the repository\n",
       "        corresponding to ``github_url`` for code to include in the run\n",
       "        (default: ``master``).\n",
       "    commit_ref (str, optional): git commit hash to use (default: ``HEAD``).\n",
       "    name (str, optional): Name of the model server. Defaults to the model name.\n",
       "    node_group (str, optional): Name of the node group to serve from. Defaults to the\n",
       "        default node group.\n",
       "    classname (str, optional): Name of the ``Predictor`` class. Only required if more then\n",
       "        one predictor exists in the entrypoint.\n",
       "    pip_packages (:obj:`list` of :obj:`str`, optional): pip dependencies (default:\n",
       "        ``None``). For example: ``[\"moviepy\", \"scikit-image\"]``.\n",
       "    apt_packages (:obj:`list` of :obj:`str`, optional): apt dependencies (default:\n",
       "        ``None``). For example: ``[\"python-tk\", \"ffmpeg\"]``\n",
       "    conda_file (str, optional): a path to a conda requirements file.\n",
       "    requirements_file (str, optional): a path to a pip requirements file.\n",
       "    envvars (:obj:`dict` of :obj:`str` -> :obj:`str`, optional): name to value mapping of\n",
       "        environment variables for the server (default: ``None``).\n",
       "    attached_resources (:obj:`dict` of :obj:`str` -> :obj:`str`, optional): resource name\n",
       "        to mountpoint mapping of attached resouces for the run (default: ``None``). For\n",
       "        example: ``{\"runs/42\" : \"/mnt/data\"}``\n",
       "    resource_requirements (:obj:`dict` of :obj:`str` -> :obj:`str`, optional):\n",
       "        configuration mapping for node resource requirements: CPU, GPU, RAM, etcetera.\n",
       "        Has sane default values.\n",
       "    num_processes (:obj:`int`): The number of processes to run the model server on. By\n",
       "        default this is ``(2 * numberOfCores) + 1``, or equal to the available GPUs if\n",
       "        applicable.\n",
       "    pod_autoscale_config (:obj:`dict` of :obj:`str` -> :obj:`str`, optional):\n",
       "        configuration mapping for pod autoscaling: ``min_pods``, ``max_pods``,\n",
       "        ``target_cpu_utilization``, ``target_requests_per_second``. Has sane default\n",
       "        values.\n",
       "    enable_batching (:obj:`bool`, optional): Whether or not to enable model server\n",
       "        batching. Defaults to ``False``.\n",
       "    batching_config (:obj:`dict` of :obj:`str` -> :obj:`int`, optional): If model server\n",
       "        batching is enabled, the values passed to this parameter are used to configure it.\n",
       "        If left empty, the default batching parameter values will be used. Has two keys:\n",
       "        ``max_batch_size`` and ``request_timeout``.\n",
       "    description: (:obj:`str`, optional): Model server description, defaults to ``None``.\n",
       "    debug (:obj:`bool`, optional): Launches the model server in debug mode. Should not be\n",
       "        used in production.\n",
       "\n",
       "Raises:\n",
       "     :py:class:`~spell.api.exceptions.ClientException`: an error occured.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Desktop/spell/python/spell/client/servers.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client.servers.serve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.servers.serve(\n",
    "    entrypoint=\"server/serve.py\",\n",
    "    model=\"cnn-cifar10:v1\",\n",
    "    github_url=\"https://github.com/spellml/cnn-cifar10.git\",\n",
    "    name=\"cifar10\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = client.servers.get(\"cifar10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `healthcheck` to hit the model server healthcheck endpoint, or use `predict` to get a prediction from the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server.healthcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class': 'Cat'}\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "img = Image.open(\"/path/to/cat.jpg\")\n",
    "img.convert(\"RGB\")\n",
    "buf = BytesIO()\n",
    "img.save(buf, format=\"JPEG\")\n",
    "img_str = base64.b64encode(buf.getvalue())\n",
    "\n",
    "resp = server.predict({\n",
    "    \"image\": img_str.decode(\"utf8\"),\n",
    "    \"format\": \"JPEG\"\n",
    "})\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access server logs (which are organized by pod ID) with `logs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelServerPod(id=1, created_at=datetime.datetime(2021, 1, 26, 22, 46, 21, 526626, tzinfo=tzutc()), ready_at=datetime.datetime(2021, 1, 26, 22, 46, 58, 2506, tzinfo=tzutc()), deleted_at=datetime.datetime(2021, 2, 11, 16, 56, 36, 564970, tzinfo=tzutc())),\n",
       " ModelServerPod(id=2, created_at=datetime.datetime(2021, 2, 11, 16, 56, 42, 470212, tzinfo=tzutc()), ready_at=datetime.datetime(2021, 2, 11, 16, 57, 27, 975144, tzinfo=tzutc()), deleted_at=datetime.datetime(2021, 3, 29, 18, 49, 16, 565075, tzinfo=tzutc())),\n",
       " ModelServerPod(id=3, created_at=datetime.datetime(2021, 4, 1, 0, 39, 53, 62144, tzinfo=tzutc()), ready_at=datetime.datetime(2021, 4, 1, 0, 40, 35, 563043, tzinfo=tzutc()))]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server.pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelServerLogEntry(log='Pod created. Waiting to be assigned to a machine...'),\n",
       " ModelServerLogEntry(log='Pod assigned to machine . Initializing pod...'),\n",
       " ModelServerLogEntry(log='Downloading model files and any mount files...'),\n",
       " ModelServerLogEntry(log='Download complete. Fetching image for server...'),\n",
       " ModelServerLogEntry(log='Image fetch complete. Starting server...')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(server.logs(1))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course you can `start`, `stop`, and `update` servers from the Python API as well.\n",
    "\n",
    "For more server methods refer to the [model server docs](https://dev.spell.ml/docs/pythonModelServers/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('spell-dev': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "interpreter": {
   "hash": "32379b01ed111356854718d637a6e727cd0803e2dd18d00055d66bad87dcce6d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}