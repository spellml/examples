{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparameter-search\n",
    "\n",
    "![](https://i.imgur.com/ewmZvLw.png)\n",
    "\n",
    "<div style=\"background-color: #fff; box-shadow: 0 2px 4px 0 rgba(0,0,0,0.2); padding: 30px; padding-top: 24px; margin: 0px 40px\">\n",
    "This Jupyter notebook is the code compliment to the blog post <b><a href=\"https://spell.run/blog/an-introduction-to-hyperparameter-search-with-cifar10-Xo8_6BMAACEAkwVs\">An introduction to hyperparameter search with CIFAR10</a></b>.\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "## prerequisites\n",
    "\n",
    "You will need:\n",
    "* An account on [Spell for Teams](https://spell.run/pricing) (hyperparameter search is not currently available in the free Spell Community product).\n",
    "* To have the `keras` and `spell` Python packages installed in your local environment. Alternatively, you can launch this notebook from a Spell workspace by running the following CLI command (requires having the `spell` package installed):\n",
    "\n",
    "```python\n",
    "spell jupyter \\\n",
    "    --lab \\\n",
    "    --github-url https://github.com/spellrun/spell-examples.git \\\n",
    "    hyper-demo-workspace\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup\n",
    "\n",
    "This demo uses a `keras` model trained on CIFAR10. [CIFAR10](https://en.wikipedia.org/wiki/CIFAR-10) is a very popular benchmark dataset for computer vision classification, containing 60,000 32x32 color images in 10 different classes. This example was taken straight from the [Keras examples](https://keras.io/examples/cifar10_cnn/). We've wrapped the model in a training script (using `argparse`) so that it takes the following hyperparameters as input:\n",
    "\n",
    "* `conv2_filter` &mdash; the size of the convolutional network filters, e.g. the dimensionality of the pixel grids that will be passed over the image.\n",
    "* `conv2_kernel` &mdash; the number of nodes to include in the convolutional layers.\n",
    "* `dropout_1`, `dropout_2`, `dropout_3` &mdash; Input convolutional block, hidden convolutional block, and output dropout values, respectively.\n",
    "* `dense_layer` &mdash; the number of nodes to include in the dense output layer.\n",
    "\n",
    "If you are not familiar with `argparse` check out `basic.py`, also in this repo folder, for an extremely minimal, bare-bones example of how it works. It boils down to the following:\n",
    "\n",
    "```python\n",
    "# create an argument parser and attach user-settable arguments to it\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--epochs', type=int, dest='epochs', default=50)\n",
    "\n",
    "# fetch those arguments; in this case args will be a dict containing a epochs key if the script\n",
    "# runner provided an epochs value, and 50 if it didn't.\n",
    "args = parser.parse_args()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cifar10_cnn.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cifar10_cnn.py\n",
    "'''\n",
    "This example is modified from https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py\n",
    "\n",
    "#Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "\n",
    "It gets to 75% validation accuracy in 25 epochs, and 79% after 50 epochs.\n",
    "(it's still underfitting at that point, though).\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--epochs', type=int, dest='epochs', default=50)\n",
    "parser.add_argument('--learning_rate', type=float, dest='learning_rate', default=0.0001)\n",
    "parser.add_argument('--conv2_filter', type=int, dest='conv2_filter', default=64)\n",
    "parser.add_argument('--conv2_kernel', type=int, dest='conv2_kernel', default=3)\n",
    "parser.add_argument('--dense_layer', type=int, dest='dense_layer', default=512)\n",
    "\n",
    "parser.add_argument('--dropout_1', type=float, dest='dropout_1', default=0.25)\n",
    "parser.add_argument('--dropout_2', type=float, dest='dropout_2', default=0.25)\n",
    "parser.add_argument('--dropout_3', type=float, dest='dropout_3', default=0.5)\n",
    "args = parser.parse_args()\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = args.epochs\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(args.dropout_1))\n",
    "\n",
    "model.add(Conv2D(args.conv2_filter, (args.conv2_kernel, args.conv2_kernel), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(args.conv2_filter, (args.conv2_kernel, args.conv2_kernel)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(args.dropout_2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(args.dense_layer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(args.dropout_3))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=args.learning_rate, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        # NOTE added to fix crash (https://github.com/keras-team/keras/issues/11874)\n",
    "                        steps_per_epoch=len(x_train) // batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# Save trained model.\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_json = model.to_json()\n",
    "model_json_path = os.path.join(save_dir, \"model.json\")\n",
    "with open(model_json_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "print('Saved model json at %s ' % model_json_path)\n",
    "model_weights_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_weights_path)\n",
    "print('Saved trained model weights at %s ' % model_weights_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can verify that this training script works locally by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python cifar10_cnn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Spell workspace will not log you in by default. If you are running this notebook from inside of a Spell workspace you will need to run the following command, replacing `YOUR_EMAIL` with your Spell email and `YOUR_PASSWORD` with your Spell password:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !spell login --identity YOUR_EMAIL --password YOUR_PASSWORD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## launching the searches\n",
    "\n",
    "We are now ready to launch our hyperparameter searches!\n",
    "\n",
    "Note that the following commands will launch up to 18 simultaneous K80 runs, each of which will take approximately 30 minutes to execute, for a total cost of around 10$ per search in cloud compute costs.\n",
    "\n",
    "If you are just testing this feature out, try running `spell hyper grid` with a more constrained set of `param` values, or running `spell hyper random` or `spell hyper bayesian` with a smaller `num-runs` value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `spell hyper grid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mðŸ’« Casting hyperparameter search #6â€¦\n",
      "\u001b[0mconv2_filter    dense_layer    dropout_3    Run ID\n",
      "16              32             0.2          184\n",
      "16              64             0.2          185\n",
      "16              128            0.2          186\n",
      "16              32             0.5          187\n",
      "16              64             0.5          188\n",
      "16              128            0.5          189\n",
      "72              32             0.2          190\n",
      "72              64             0.2          191\n",
      "72              128            0.2          192\n",
      "72              32             0.5          193\n",
      "72              64             0.5          194\n",
      "72              128            0.5          195\n",
      "128             32             0.2          196\n",
      "128             64             0.2          197\n",
      "128             128            0.2          198\n",
      "128             32             0.5          199\n",
      "128             64             0.5          200\n",
      "128             128            0.5          201\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell hyper grid \\\n",
    "    --machine-type K80 \\\n",
    "    --param conv2_filter=16,72,128 \\\n",
    "    --param dense_layer=32,64,128 \\\n",
    "    --param dropout_3=0.2,0.5 \\\n",
    "    --github-url https://github.com/spellrun/spell-examples.git \\\n",
    "    # --github-ref hyper \\\n",
    "    \"python hyper/cifar10_cnn.py \\\n",
    "        --epochs 25 \\\n",
    "        --conv2_filter :conv2_filter: \\\n",
    "        --dense_layer :dense_layer: \\\n",
    "        --dropout_3 :dropout_3:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This launches the simplest type of hyperparameter search, a grid search. You specify grid search parameters by passing a comma-separated list of values to test out, e.g. `16,72,128`. A separate run will then be created, scheduled, and executed for every possible combination of the specified hyperparameters.\n",
    "\n",
    "Notice the use of the special `:hyperparameter:` syntax in the command body. At runtime Spell will plug the `hyperparameter` value set on the `param` flag into the corresponding `:hyperparameter:` value in the command body."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `spell hyper random`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mðŸ’« Casting hyperparameter search #10â€¦\n",
      "\u001b[0mconv2_filter    dense_layer    dropout_3    Run ID\n",
      "60              39             0.488294     250\n",
      "110             81             0.499862     251\n",
      "33              40             0.34271      252\n",
      "117             128            0.223744     253\n",
      "117             115            0.465318     254\n",
      "48              75             0.345887     255\n",
      "58              121            0.292594     256\n",
      "84              106            0.41578      257\n",
      "104             107            0.2267       258\n",
      "94              85             0.421738     259\n",
      "36              99             0.399534     260\n",
      "36              50             0.281066     261\n",
      "30              78             0.270079     262\n",
      "60              102            0.384012     263\n",
      "32              115            0.498942     264\n",
      "128             77             0.281639     265\n",
      "19              110            0.318054     266\n",
      "76              67             0.489551     267\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell hyper random \\\n",
    "    --machine-type K80 \\\n",
    "    --param conv2_filter=16:128:linear:int \\\n",
    "    --param dense_layer=32:128:linear:int \\\n",
    "    --param dropout_3=0.2:0.5 \\\n",
    "    --num-runs 18 \\\n",
    "    --github-url https://github.com/spellrun/spell-examples.git \\\n",
    "    # --github-ref hyper \\\n",
    "    \"python hyper/cifar10_cnn.py \\\n",
    "        --epochs 25 \\\n",
    "        --conv2_filter :conv2_filter: \\\n",
    "        --dense_layer :dense_layer: \\\n",
    "        --dropout_3 :dropout_3:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This launches a random hyperparameter search. In random hyperparameter search, instead of picking a value from a list, Spell will pick a value from a range of values at random. For example, `conv2_filter` is set to the range `16:128`, so Spell might randomly pick the values `17, 125, 21, 99, 101, ...`.\n",
    "\n",
    "Random search outperforms grid search in most practical settings. A good rule of thumb is to switch to using random search whenever you are performing hyperparameter search in more than three dimensions.\n",
    "\n",
    "The new `num-runs` required parameter specified how many times this process should be repeated. In this case I've specified `18` to match the fidelity of the grid search we just ran (which also executed 3 * 3 * 2 = 18 runs).\n",
    "\n",
    "Note that the `param` flag also supports a few other useful features. The full parameter signature is:\n",
    "\n",
    "```\n",
    "NAME=VALUE[,VALUE,VALUE,...] or NAME=MIN:MAX[:linear|log|reverse_log[:int|float]]\n",
    "```\n",
    "\n",
    "So instead of passing a range of values, e.g. `16:128`, you can pass a list of them, e.g. `16, 32, 64, 128`. Spell random will then choose these values at random instead of picking from out of the range. Be careful not to overuse this feature, however, as it basically turns your random search back into a grid search.\n",
    "\n",
    "You can also specifiy the point selection strategy. The default strategy is `linear`, which samples points, well, linearly. But you can use a `log` or `reverse_log` strategy instead.\n",
    "\n",
    "Finally, you can specify whether you want to pick integers (`int`) or floating point numbers (`float`) out of the range. This is important because for many parameters (for example, how many nodes should each layer have?), only whole numbers make sense. Spell will default to a floating point number, so to pick whole numbers linearly out of a range of values you will need to use the syntax `16:128:linear:int`, as we did here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `spell hyper bayesian`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mðŸ’« Casting hyperparameter search #12â€¦\n",
      "\u001b[0mconv2_filter    dense_layer    dropout_3    Run ID\n",
      "29              107            0.45447      275\n",
      "62              49             0.252026     276\n",
      "40              124            0.214014     277\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell hyper bayesian \\\n",
    "    --machine-type K80 \\\n",
    "    --param conv2_filter=16:128:int \\\n",
    "    --param dense_layer=32:128:int \\\n",
    "    --param dropout_3=0.2:0.5 \\\n",
    "    --num-runs 18 \\\n",
    "    --parallel-runs 3 \\\n",
    "    --metric keras/val_accuracy \\\n",
    "    --metric-agg last \\\n",
    "    --github-url https://github.com/spellrun/spell-examples.git \\\n",
    "    # --github-ref hyper \\\n",
    "    \"python hyper/cifar10_cnn.py \\\n",
    "        --epochs 25 \\\n",
    "        --conv2_filter :conv2_filter: \\\n",
    "        --dense_layer :dense_layer: \\\n",
    "        --dropout_3 :dropout_3:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last type of hyperparameter search that Spell supports is Bayesian search. In Bayesian search a [Bayesian](https://en.wikipedia.org/wiki/Bayesian_probability) selection algorithm is used to bias the search points selected towards those that the algorithm has deemed probable based on the results of prior selections.\n",
    "\n",
    "This is the most complex type of hyperparameter search, which is why it's also the one with the largest number of parameters.\n",
    "\n",
    "`parallel-runs` controls how many runs Spell will try to schedule and execute simultaneously. If this value is set to 1, the search will be performed completely sequentially, and each run will have access to the complete prior history of runs with which to make a decision about what values to choose next. If this value were set to 18, equaling the `num-runs`, we'd schedule every run simultaneously, essentially falling back to random search. Every other number in between offers a tradeoff between how much information the model has as its prior and how quickly the search finishes running.\n",
    "\n",
    "`metric` controls the metric the Bayesian optimization algorithm is attempting to optimize. In this case we have chosen the `keras/val_accuracy`, e.g. the validation accuracy as reported by `keras`, as our target. `keras` registers certain metrics in an automatic way as part of its training process, and Spell is able to use this information to connect to and report these metric values automatically. For other machine learning frameworks or other types of model metrics you will need to use the Spell Python API to register and report your own custom model metrics.\n",
    "\n",
    "The last new parameter is `metric-agg`. This controls how the metric history is to be \"compressed\" into a single number that the Bayesian hyperparameter search algorithm will use for determining model fit. In this case we set it to `last`, e.g. to the final accuracy value reported by the model training script. `avg`, `min` (useful if the metric is a loss function), and `max` are also options.\n",
    "\n",
    "An example of hyperparameter search with custom metrics enables will be the subject of a future notebook. For now refer to the instructions on the [Metrics](https://spell.run/docs/metrics) page in the docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluating results\n",
    "\n",
    "The results of your hyperparameter searches are available from the \"Hyperparamater Searches\" page in the [web console](https://web.spell.run/aleksey/hyper-searches).\n",
    "\n",
    "This page provides an overview of the hyperparameter search points as well as three different visualizations of model performance: a line chart, a table, and a facet chart. For more information on this feature and helpful tips for interpretting these plots see the [Hyperparameter searches](https://spell.run/docs/hyper_searches) page in our docs.\n",
    "\n",
    "In addition to evaluating model performance in-situ on the web you may also want to pull the metrics down to your local machine so that you may visualize them yourself. Here's a quick recipe for doing so using the Python API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spell.client\n",
    "\n",
    "# if running in a Spell workspace you will need to log in first for this to work:\n",
    "# !spell login --identity YOUR_EMAIL --password YOUR_PASSWORD\n",
    "client = spell.client.from_environment()\n",
    "\n",
    "# 196 to 202 happens to be the range of run IDs associated with this search which\n",
    "# we've selected. Replace these  values with the values associated with your own\n",
    "# hyperparameter search.\n",
    "metrics = []\n",
    "for run_id in range(196, 202):\n",
    "    run = client.runs.get(run_id)\n",
    "    \n",
    "    # we return the metrics data as a generator\n",
    "    metric = run.metrics(\"keras/val_accuracy\")\n",
    "    \n",
    "    df = pd.DataFrame(metric, columns=[\"timestamp\", \"epoch\", \"val_accuracy\"])\n",
    "    df['run_id'] = run_id\n",
    "    metrics.append(df)\n",
    "\n",
    "metrics = pd.concat(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-07 20:21:36.117924+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3953</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-07 20:22:29.501385+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4583</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-07 20:23:22.638722+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4972</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-07 20:24:16.121827+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5305</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-07 20:25:11.049345+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5272</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-04-07 20:39:45.127875+00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7338</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-04-07 20:40:37.629362+00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-04-07 20:41:30.147770+00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>0.7309</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-04-07 20:42:22.784600+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>0.7514</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-04-07 20:43:15.946202+00:00</td>\n",
       "      <td>24</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp  epoch  val_accuracy  run_id\n",
       "0  2020-04-07 20:21:36.117924+00:00      0        0.3953     196\n",
       "1  2020-04-07 20:22:29.501385+00:00      1        0.4583     196\n",
       "2  2020-04-07 20:23:22.638722+00:00      2        0.4972     196\n",
       "3  2020-04-07 20:24:16.121827+00:00      3        0.5305     196\n",
       "4  2020-04-07 20:25:11.049345+00:00      4        0.5272     196\n",
       "..                              ...    ...           ...     ...\n",
       "20 2020-04-07 20:39:45.127875+00:00     20        0.7338     201\n",
       "21 2020-04-07 20:40:37.629362+00:00     21        0.7286     201\n",
       "22 2020-04-07 20:41:30.147770+00:00     22        0.7309     201\n",
       "23 2020-04-07 20:42:22.784600+00:00     23        0.7514     201\n",
       "24 2020-04-07 20:43:15.946202+00:00     24        0.7320     201\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd052795cd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "metrics.groupby('run_id').val_accuracy.max().plot.bar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
