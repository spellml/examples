{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reentrancy-demo\n",
    "\n",
    "![](https://i.imgur.com/NYowq6j.png)\n",
    "\n",
    "<div style=\"background-color: #fff; box-shadow: 0 2px 4px 0 rgba(0,0,0,0.2); padding: 30px; padding-top: 24px; margin: 0px 40px\">\n",
    "This Jupyter notebook is the code compliment to the blog posts <b><a href=\"https://spell.run/blog/automated-machine-failure-recovery-Xp3TEhEAACUAYwPM\">Automating GPU machine failure recovery in Google Compute Engine</a></b> and <b><a href=\"https://spell.run/blog/reducing-gpu-model-training-costs-using-spot-XqtgJBAAACMAR6h8\">Reducing GPU model training costs by 66% using spot instances</a></b>.\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "## prerequisites\n",
    "\n",
    "You will need:\n",
    "* An account on Spell.\n",
    "* A copy of the [250 Segmented Bob Ross Images](https://www.kaggle.com/residentmario/segmented-bob-ross-images) dataset from Kaggle. Download this dataset, unzip it, and upload it to SpellFS by running e.g. `spell upload ~/Downloads/segmented-bob-ross-images`. The files should land in the `uploads/segmented-bob-ross-images` directory in Spell.\n",
    "* The `pytorch` and `spell` Python packages installed in your local environment. Alternatively, you can launch this notebook from a Spell workspace by running the following CLI command (requires having the `spell` package installed):\n",
    "\n",
    "```python\n",
    "spell jupyter \\\n",
    "    --lab \\\n",
    "    --github-url https://github.com/spellrun/spell-examples.git \\\n",
    "    spot-demo-workspace\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a non-reentrant training script\n",
    "\n",
    "A script or pipeline is said to be **reentrant** if it can safely be rerun after terminating or failing midway through execution.\n",
    "\n",
    "To demonstrate what this means in the context of machine learning training, take a look at the following `pytorch` training script. This script trains a [UNet](https://arxiv.org/abs/1505.04597) image segmentation model on the [250 Segmented Bob Ross Images](https://www.kaggle.com/residentmario/segmented-bob-ross-images) dataset from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting unet.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile unet.py\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1_1 = nn.Conv2d(3, 64, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_1_1.weight)\n",
    "        self.relu_1_2 = nn.ReLU()\n",
    "        self.norm_1_3 = nn.BatchNorm2d(64)\n",
    "        self.conv_1_4 = nn.Conv2d(64, 64, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_1_4.weight)\n",
    "        self.relu_1_5 = nn.ReLU()\n",
    "        self.norm_1_6 = nn.BatchNorm2d(64)\n",
    "        self.pool_1_7 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv_2_1 = nn.Conv2d(64, 128, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_2_1.weight)        \n",
    "        self.relu_2_2 = nn.ReLU()\n",
    "        self.norm_2_3 = nn.BatchNorm2d(128)\n",
    "        self.conv_2_4 = nn.Conv2d(128, 128, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_2_4.weight)        \n",
    "        self.relu_2_5 = nn.ReLU()\n",
    "        self.norm_2_6 = nn.BatchNorm2d(128)\n",
    "        self.pool_2_7 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv_3_1 = nn.Conv2d(128, 256, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_3_1.weight)\n",
    "        self.relu_3_2 = nn.ReLU()\n",
    "        self.norm_3_3 = nn.BatchNorm2d(256)\n",
    "        self.conv_3_4 = nn.Conv2d(256, 256, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_3_4.weight)\n",
    "        self.relu_3_5 = nn.ReLU()\n",
    "        self.norm_3_6 = nn.BatchNorm2d(256)\n",
    "        self.pool_3_7 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv_4_1 = nn.Conv2d(256, 512, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_4_1.weight)\n",
    "        self.relu_4_2 = nn.ReLU()\n",
    "        self.norm_4_3 = nn.BatchNorm2d(512)\n",
    "        self.conv_4_4 = nn.Conv2d(512, 512, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_4_4.weight)\n",
    "        self.relu_4_5 = nn.ReLU()\n",
    "        self.norm_4_6 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        # deconv is the '2D transposed convolution operator'\n",
    "        self.deconv_5_1 = nn.ConvTranspose2d(512, 256, (2, 2), 2)\n",
    "        # 61x61 -> 48x48 crop\n",
    "        self.c_crop_5_2 = lambda x: x[:, :, 6:54, 6:54]\n",
    "        self.concat_5_3 = lambda x, y: torch.cat((x, y), dim=1)\n",
    "        self.conv_5_4 = nn.Conv2d(512, 256, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_5_4.weight)        \n",
    "        self.relu_5_5 = nn.ReLU()\n",
    "        self.norm_5_6 = nn.BatchNorm2d(256)\n",
    "        self.conv_5_7 = nn.Conv2d(256, 256, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_5_7.weight)\n",
    "        self.relu_5_8 = nn.ReLU()\n",
    "        self.norm_5_9 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.deconv_6_1 = nn.ConvTranspose2d(256, 128, (2, 2), 2)\n",
    "        # 121x121 -> 88x88 crop\n",
    "        self.c_crop_6_2 = lambda x: x[:, :, 17:105, 17:105]\n",
    "        self.concat_6_3 = lambda x, y: torch.cat((x, y), dim=1)\n",
    "        self.conv_6_4 = nn.Conv2d(256, 128, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_6_4.weight)\n",
    "        self.relu_6_5 = nn.ReLU()\n",
    "        self.norm_6_6 = nn.BatchNorm2d(128)\n",
    "        self.conv_6_7 = nn.Conv2d(128, 128, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_6_7.weight)\n",
    "        self.relu_6_8 = nn.ReLU()\n",
    "        self.norm_6_9 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.deconv_7_1 = nn.ConvTranspose2d(128, 64, (2, 2), 2)\n",
    "        # 252x252 -> 168x168 crop\n",
    "        self.c_crop_7_2 = lambda x: x[:, :, 44:212, 44:212]\n",
    "        self.concat_7_3 = lambda x, y: torch.cat((x, y), dim=1)\n",
    "        self.conv_7_4 = nn.Conv2d(128, 64, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_7_4.weight)\n",
    "        self.relu_7_5 = nn.ReLU()\n",
    "        self.norm_7_6 = nn.BatchNorm2d(64)\n",
    "        self.conv_7_7 = nn.Conv2d(64, 64, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_7_7.weight)        \n",
    "        self.relu_7_8 = nn.ReLU()\n",
    "        self.norm_7_9 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # 1x1 conv ~= fc; n_classes = 9\n",
    "        self.conv_8_1 = nn.Conv2d(64, 9, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1_1(x)\n",
    "        x = self.relu_1_2(x)\n",
    "        x = self.norm_1_3(x)\n",
    "        x = self.conv_1_4(x)\n",
    "        x = self.relu_1_5(x)\n",
    "        x_residual_1 = self.norm_1_6(x)\n",
    "        x = self.pool_1_7(x_residual_1)\n",
    "        \n",
    "        x = self.conv_2_1(x)\n",
    "        x = self.relu_2_2(x)\n",
    "        x = self.norm_2_3(x)\n",
    "        x = self.conv_2_4(x)\n",
    "        x = self.relu_2_5(x)\n",
    "        x_residual_2 = self.norm_2_6(x)\n",
    "        x = self.pool_2_7(x_residual_2)\n",
    "        \n",
    "        x = self.conv_3_1(x)\n",
    "        x = self.relu_3_2(x)\n",
    "        x = self.norm_3_3(x)\n",
    "        x = self.conv_3_4(x)\n",
    "        x = self.relu_3_5(x)\n",
    "        x_residual_3 = self.norm_3_6(x)\n",
    "        x = self.pool_3_7(x_residual_3)\n",
    "        \n",
    "        x = self.conv_4_1(x)\n",
    "        x = self.relu_4_2(x)\n",
    "        x = self.norm_4_3(x)        \n",
    "        x = self.conv_4_4(x)\n",
    "        x = self.relu_4_5(x)\n",
    "        x = self.norm_4_6(x)\n",
    "        \n",
    "        x = self.deconv_5_1(x)\n",
    "        x = self.concat_5_3(self.c_crop_5_2(x_residual_3), x)\n",
    "        x = self.conv_5_4(x)\n",
    "        x = self.relu_5_5(x)\n",
    "        x = self.norm_5_6(x)\n",
    "        x = self.conv_5_7(x)\n",
    "        x = self.relu_5_8(x)\n",
    "        x = self.norm_5_9(x)\n",
    "        \n",
    "        x = self.deconv_6_1(x)\n",
    "        x = self.concat_6_3(self.c_crop_6_2(x_residual_2), x)\n",
    "        x = self.conv_6_4(x)\n",
    "        x = self.relu_6_5(x)\n",
    "        x = self.norm_6_6(x)\n",
    "        x = self.conv_6_7(x)\n",
    "        x = self.relu_6_8(x)\n",
    "        x = self.norm_6_9(x)\n",
    "        \n",
    "        x = self.deconv_7_1(x)\n",
    "        x = self.concat_7_3(self.c_crop_7_2(x_residual_1), x)\n",
    "        x = self.conv_7_4(x)\n",
    "        x = self.relu_7_5(x)\n",
    "        x = self.norm_7_6(x)\n",
    "        x = self.conv_7_7(x)\n",
    "        x = self.relu_7_8(x)\n",
    "        x = self.norm_7_9(x)\n",
    "        \n",
    "        x = self.conv_8_1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from unet import UNet\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "class BobRossSegmentedImagesDataset(Dataset):\n",
    "    def __init__(self, dataroot):\n",
    "        super().__init__()\n",
    "        self.dataroot = dataroot\n",
    "        self.imgs = list((self.dataroot / 'train' / 'images').rglob('*.png'))\n",
    "        self.segs = list((self.dataroot / 'train' / 'labels').rglob('*.png'))\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((164, 164)),\n",
    "            transforms.Pad(46, padding_mode='reflect'),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                            mean=(0.459387, 0.46603974, 0.4336706),\n",
    "                            std=(0.06098535, 0.05802868, 0.08737113)\n",
    "            )\n",
    "        ])\n",
    "        self.color_key = {\n",
    "            3 : 0,\n",
    "            5: 1,\n",
    "            10: 2,\n",
    "            14: 3,\n",
    "            17: 4,\n",
    "            18: 5,\n",
    "            22: 6,\n",
    "            27: 7,\n",
    "            61: 8\n",
    "        }\n",
    "        assert len(self.imgs) == len(self.segs)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        def translate(x):\n",
    "            return self.color_key[x]\n",
    "        translate = np.vectorize(translate)\n",
    "        \n",
    "        img = Image.open(self.imgs[i])\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        seg = Image.open(self.segs[i])\n",
    "        seg = seg.resize((256, 256), Image.NEAREST)\n",
    "        \n",
    "        seg = translate(np.array(seg)).astype('int64')\n",
    "        \n",
    "        # Additionally, the original UNet implementation outputs a segmentation map\n",
    "        # for a subset of the overall image, not the image as a whole! With this input\n",
    "        # size the segmentation map targeted is a (164, 164) center crop.\n",
    "        seg = seg[46:210, 46:210]\n",
    "        \n",
    "        return img, seg\n",
    "\n",
    "dataroot = Path('/mnt/segmented-bob-ross-images/')\n",
    "dataset = BobRossSegmentedImagesDataset(dataroot)\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=8)\n",
    "\n",
    "model = UNet()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=32)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    losses = []\n",
    "\n",
    "    for i, (batch, segmap) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch = batch.cuda()\n",
    "        segmap = segmap.cuda()\n",
    "\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, segmap)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        curr_loss = loss.item()\n",
    "        losses.append(curr_loss)\n",
    "\n",
    "    print(f'Finished epoch {epoch}.')\n",
    "\n",
    "torch.save(model.state_dict(), '50_net.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This training script is not reentrant.** Saving the model to disk is the very last thing this training script does. If the run executing this training script gets interrupted, all training progress the model made prior to termination is lost forever!\n",
    "\n",
    "It's unsafe to assume that the machine running the script will actually succeed in executing it from start to finish:\n",
    "\n",
    "* The machine might experience a hardware failure, forcing early termination.\n",
    "* If the machine is an on-demand Compute Engine instance on GCP, and it has been live for six hours or longer, it may be randomly forced into the `REPAIRING` state and self-terminate.\n",
    "* If the machine is a spot instance on AWS or a preemptible instance on GCP, it may get reclaimed by the vendor.\n",
    "\n",
    "If the model is small, it's cheap enough to simply launch a new training job from scratch when the old one fails.\n",
    "\n",
    "If the model is large and complex, things are different. State-of-the-art user-facing deep learning models often take hundreds (if not thousands) of dollars to train once. In these kinds of scenarios losing all of your progress is prohibitively expensive and potentially a huge source of delay for your project.\n",
    "\n",
    "## reentrant training script\n",
    "To protect against unexpected failure and/or take advantage of spot instance cost savings, make your training script reentrant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_reentrant.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_reentrant.py\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from unet import UNet\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "# Instead of always starting the zeroeth epoch, check if the user passed a checkpoint.\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--from-checkpoint', type=str, dest='checkpoint', default='')\n",
    "args = parser.parse_args()\n",
    "if args.checkpoint:\n",
    "    first_remaining_epoch = int(args.checkpoint.split('_')[0]) + 1\n",
    "    EPOCHS = range(first_remaining_epoch, NUM_EPOCHS)\n",
    "else:\n",
    "    EPOCHS = range(NUM_EPOCHS)\n",
    "\n",
    "class BobRossSegmentedImagesDataset(Dataset):\n",
    "    def __init__(self, dataroot):\n",
    "        super().__init__()\n",
    "        self.dataroot = dataroot\n",
    "        self.imgs = list((self.dataroot / 'train' / 'images').rglob('*.png'))\n",
    "        self.segs = list((self.dataroot / 'train' / 'labels').rglob('*.png'))\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((164, 164)),\n",
    "            transforms.Pad(46, padding_mode='reflect'),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                            mean=(0.459387, 0.46603974, 0.4336706),\n",
    "                            std=(0.06098535, 0.05802868, 0.08737113)\n",
    "            )\n",
    "        ])\n",
    "        self.color_key = {\n",
    "            3 : 0,\n",
    "            5: 1,\n",
    "            10: 2,\n",
    "            14: 3,\n",
    "            17: 4,\n",
    "            18: 5,\n",
    "            22: 6,\n",
    "            27: 7,\n",
    "            61: 8\n",
    "        }\n",
    "        assert len(self.imgs) == len(self.segs)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        def translate(x):\n",
    "            return self.color_key[x]\n",
    "        translate = np.vectorize(translate)\n",
    "        \n",
    "        img = Image.open(self.imgs[i])\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        seg = Image.open(self.segs[i])\n",
    "        seg = seg.resize((256, 256), Image.NEAREST)\n",
    "        \n",
    "        seg = translate(np.array(seg)).astype('int64')\n",
    "        \n",
    "        # Additionally, the original UNet implementation outputs a segmentation map\n",
    "        # for a subset of the overall image, not the image as a whole! With this input\n",
    "        # size the segmentation map targeted is a (164, 164) center crop.\n",
    "        seg = seg[46:210, 46:210]\n",
    "        \n",
    "        return img, seg\n",
    "\n",
    "dataroot = Path('/mnt/segmented-bob-ross-images/')\n",
    "dataset = BobRossSegmentedImagesDataset(dataroot)\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=8)\n",
    "\n",
    "# Instead of always initializing an empty model, initialize from the checkpoints\n",
    "# file if one is available.\n",
    "model = UNet()\n",
    "model.cuda()\n",
    "if args.checkpoint:\n",
    "    model.load_state_dict(torch.load(f'/mnt/checkpoints/{args.checkpoint}'))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=32)\n",
    "\n",
    "for epoch in EPOCHS:\n",
    "    losses = []\n",
    "\n",
    "    for i, (batch, segmap) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch = batch.cuda()\n",
    "        segmap = segmap.cuda()\n",
    "\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, segmap)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        curr_loss = loss.item()\n",
    "        losses.append(curr_loss)\n",
    "\n",
    "    print(f'Finished epoch {epoch}.')\n",
    "\n",
    "    # Save the model checkpoints file every 5 epochs\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(model.state_dict(), f'{epoch}_net.pth')\n",
    "        print(f'Saved model to {epoch}_net.pth.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This updated script uses the [PyTorch model saving and loading facilities](https://pytorch.org/tutorials/beginner/saving_loading_models.html) to checkpoint the file every five epochs. The script is now parameterizable with a `--from-checkpoint` flag which, if set, specifies the path to the checkpoints file that model training is to be restarted from.\n",
    "\n",
    "It's easy to use this updated training script hand-in-hand with the Spell API to ensure that you can restart right where you left off. Here's how. First, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0müí´ Casting spell #307‚Ä¶\n",
      "\u001b[0m‚ú® Stop viewing logs with ^C\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m‚ú® Machine_Requested‚Ä¶ done\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m‚ú® Building‚Ä¶ done tagged registry.spell:80/remote_content_307:d1958944e‚Ä¶‚Ä¶0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m‚ú® Mounting‚Ä¶ done\n",
      "\u001b[0m‚ú® \u001b[0mRun is running\n",
      "\u001b[0mFinished epoch 0.\n",
      "\u001b[0mSaved model to 0_net.pth.\n",
      "\u001b[0mFinished epoch 1.\n",
      "\u001b[0mFinished epoch 2.\n",
      "\u001b[0mFinished epoch 3.\n",
      "\u001b[0mFinished epoch 4.\n",
      "\u001b[0mFinished epoch 5.\n",
      "\u001b[0mSaved model to 5_net.pth.\n",
      "\u001b[0mFinished epoch 6.\n",
      "\u001b[0mFinished epoch 7.\n",
      "\u001b[0mFinished epoch 8.\n",
      "\u001b[0mFinished epoch 9.\n",
      "\u001b[0mFinished epoch 10.\n",
      "\u001b[0mSaved model to 10_net.pth.\n",
      "\u001b[0mFinished epoch 11.\n",
      "\u001b[0mFinished epoch 12.\n",
      "\u001b[0mFinished epoch 13.\n",
      "\u001b[0mFinished epoch 14.\n",
      "\u001b[0mFinished epoch 15.\n",
      "\u001b[0mSaved model to 15_net.pth.\n",
      "\u001b[0mFinished epoch 16.\n",
      "\u001b[0mFinished epoch 17.\n",
      "\u001b[0mFinished epoch 18.\n",
      "\u001b[0mFinished epoch 19.\n",
      "\u001b[0mFinished epoch 20.\n",
      "\u001b[0mSaved model to 20_net.pth.\n",
      "\u001b[0mFinished epoch 21.\n",
      "\u001b[0mFinished epoch 22.\n",
      "\u001b[0mFinished epoch 23.\n",
      "\u001b[0mFinished epoch 24.\n",
      "\u001b[0mFinished epoch 25.\n",
      "\u001b[0mSaved model to 25_net.pth.\n",
      "\u001b[0mFinished epoch 26.\n",
      "\u001b[0mFinished epoch 27.\n",
      "\u001b[0mFinished epoch 28.\n",
      "\u001b[0mFinished epoch 29.\n",
      "\u001b[0mFinished epoch 30.\n",
      "\u001b[0mSaved model to 30_net.pth.\n",
      "\u001b[0mFinished epoch 31.\n",
      "\u001b[0mFinished epoch 32.\n",
      "\u001b[0mFinished epoch 33.\n",
      "\u001b[0mFinished epoch 34.\n",
      "\u001b[0mFinished epoch 35.\n",
      "\u001b[0mSaved model to 35_net.pth.\n",
      "\u001b[0m^C\n",
      "\n",
      "\u001b[0m‚ú® Your run is still running remotely.\n",
      "\u001b[0m‚ú® Use 'spell kill 307' to terminate your run\n",
      "\u001b[0m‚ú® Use 'spell logs 307' to view logs again\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell run --machine-type V100 \\\n",
    "    --github-url 'https://github.com/spellrun/spell-examples.git' \\\n",
    "    --mount uploads/segmented-bob-ross-images:/mnt/segmented-bob-ross-images \\\n",
    "    --pip Pillow \\\n",
    "    \"python spot/train_reentrant.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Spell workspace will not log you in by default. If you are running this notebook from inside of a Spell workspace you will need to run the following command, replacing `YOUR_EMAIL` with your Spell email and `YOUR_PASSWORD` with your Spell password:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !spell login --identity YOUR_EMAIL --password YOUR_PASSWORD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this model training for a while, simulate an early termination by [stopping](https://spell.run/docs/run_overview#interrupting-a-run) the run (replace `RUN_ID` here with the `RUN_ID` that got assigned to this run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mStopping run 307. Use 'spell logs -f 307' to view logs while the job finishes.\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell stop 307"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the run outputs that landed in SpellFS using `spell ls`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m30854380 Apr 27 23:50   0_net.pth\n",
      "\u001b[0m30854380 Apr 27 23:50   10_net.pth\n",
      "\u001b[0m30854380 Apr 27 23:50   15_net.pth\n",
      "\u001b[0m30854380 Apr 27 23:50   20_net.pth\n",
      "\u001b[0m30854380 Apr 27 23:50   25_net.pth\n",
      "\u001b[0m30854380 Apr 27 23:50   30_net.pth\n",
      "\u001b[0m30854380 Apr 27 23:50   35_net.pth\n",
      "\u001b[0m30854380 Apr 27 23:50   5_net.pth\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell ls runs/307"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to restart where you left off you simply run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0müí´ Casting spell #309‚Ä¶\n",
      "\u001b[0m‚ú® Stop viewing logs with ^C\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m‚ú® Machine_Requested‚Ä¶ done\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m‚ú® Building‚Ä¶ done tagged registry.spell:80/remote_content_309:bfde0d448‚Ä¶‚Ä¶\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m‚ú® Mounting‚Ä¶ done\n",
      "\u001b[0m‚ú® \u001b[0mRun is running\n",
      "\u001b[0m^C\n",
      "\n",
      "\u001b[0m‚ú® Your run is still running remotely.\n",
      "\u001b[0m‚ú® Use 'spell kill 309' to terminate your run\n",
      "\u001b[0m‚ú® Use 'spell logs 309' to view logs again\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell run --machine-type V100 \\\n",
    "    --github-url 'https://github.com/spellrun/spell-examples.git' \\\n",
    "    --mount uploads/segmented-bob-ross-images:/mnt/segmented-bob-ross-images \\\n",
    "    --mount runs/307:/mnt/checkpoints/ \\\n",
    "    --pip Pillow \\\n",
    "    \"python spot/train_reentrant.py --from-checkpoint '35_net.pth'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which will train the model to completion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resumable\n",
    "\n",
    "A **resumable** training script goes one step further than a reentrant one.\n",
    "\n",
    "Spell runs executed on spot instances may be configured with a `--auto-resume` flag set. In the event the machine is reclaimed by the cloud provider, this flag instructs Spell to queue a new Spell run with the same run command and a copy of the previous run's disk image. Assuming your training script is resumable, this will make your training job robust to cloud interrupts. Almost as good as an on-demand instance at less than half the price!\n",
    "\n",
    "Here's an example. Note the addition of the `--resume` flag, which automatically finds the most recent checkpoint file and resumes from that one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_resumable.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_resumable.py\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "\n",
    "from unet import UNet\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "# Instead of always starting the zeroeth epoch, check if the user passed a checkpoint.\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--from-checkpoint', type=str, dest='checkpoint', default='')\n",
    "parser.add_argument('--resume', action='store_true')\n",
    "args = parser.parse_args()\n",
    "\n",
    "class BobRossSegmentedImagesDataset(Dataset):\n",
    "    def __init__(self, dataroot):\n",
    "        super().__init__()\n",
    "        self.dataroot = dataroot\n",
    "        self.imgs = list((self.dataroot / 'train' / 'images').rglob('*.png'))\n",
    "        self.segs = list((self.dataroot / 'train' / 'labels').rglob('*.png'))\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((164, 164)),\n",
    "            transforms.Pad(46, padding_mode='reflect'),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                            mean=(0.459387, 0.46603974, 0.4336706),\n",
    "                            std=(0.06098535, 0.05802868, 0.08737113)\n",
    "            )\n",
    "        ])\n",
    "        self.color_key = {\n",
    "            3 : 0,\n",
    "            5: 1,\n",
    "            10: 2,\n",
    "            14: 3,\n",
    "            17: 4,\n",
    "            18: 5,\n",
    "            22: 6,\n",
    "            27: 7,\n",
    "            61: 8\n",
    "        }\n",
    "        assert len(self.imgs) == len(self.segs)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        def translate(x):\n",
    "            return self.color_key[x]\n",
    "        translate = np.vectorize(translate)\n",
    "        \n",
    "        img = Image.open(self.imgs[i])\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        seg = Image.open(self.segs[i])\n",
    "        seg = seg.resize((256, 256), Image.NEAREST)\n",
    "        \n",
    "        seg = translate(np.array(seg)).astype('int64')\n",
    "        \n",
    "        # Additionally, the original UNet implementation outputs a segmentation map\n",
    "        # for a subset of the overall image, not the image as a whole! With this input\n",
    "        # size the segmentation map targeted is a (164, 164) center crop.\n",
    "        seg = seg[46:210, 46:210]\n",
    "        \n",
    "        return img, seg\n",
    "\n",
    "dataroot = Path('/mnt/segmented-bob-ross-images/')\n",
    "dataset = BobRossSegmentedImagesDataset(dataroot)\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=8)\n",
    "\n",
    "# Instead of always initializing an empty model, initialize from the checkpoints\n",
    "# file if one is available.\n",
    "model = UNet()\n",
    "model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=32)\n",
    "\n",
    "if args.resume:\n",
    "    if not os.path.exists(\"/spell/checkpoints/\") or len(os.listdir(\"/spell/checkpoints/\")) == 0:\n",
    "        EPOCHS = range(NUM_EPOCHS)\n",
    "    else:\n",
    "        checkpoint_epoch = max(\n",
    "            [int(re.findall(\"[0-9]{1,2}\", fp)[0]) for fp in os.listdir(\"/spell/checkpoints/\")]\n",
    "        )\n",
    "        model.load_state_dict(torch.load(f'/spell/checkpoints/{checkpoint_epoch}_net.pth'))\n",
    "        first_remaining_epoch = checkpoint_epoch + 1\n",
    "        EPOCHS = range(first_remaining_epoch, NUM_EPOCHS)\n",
    "elif args.checkpoint:\n",
    "    first_remaining_epoch = int(args.checkpoint.split('_')[0]) + 1\n",
    "    EPOCHS = range(first_remaining_epoch, NUM_EPOCHS)\n",
    "    model.load_state_dict(torch.load(f'/spell/checkpoints/{args.checkpoint}'))\n",
    "else:\n",
    "    EPOCHS = range(NUM_EPOCHS)\n",
    "\n",
    "for epoch in EPOCHS:\n",
    "    losses = []\n",
    "\n",
    "    for i, (batch, segmap) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch = batch.cuda()\n",
    "        segmap = segmap.cuda()\n",
    "\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, segmap)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        curr_loss = loss.item()\n",
    "        losses.append(curr_loss)\n",
    "\n",
    "    print(f'Finished epoch {epoch}.')\n",
    "\n",
    "    # Save the model checkpoints file every 5 epochs\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(model.state_dict(), f'{epoch}_net.pth')\n",
    "        print(f'Saved model to {epoch}_net.pth.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m  aleksey\n",
      "\u001b[0m  spellrun\n",
      "\u001b[0m  external-gcp\n",
      "\u001b[0m‚ûî \u001b[32mexternal-aws\u001b[0m\n",
      "\u001b[0m  spell-org\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell owner external-aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0müí´ Casting spell #144‚Ä¶\n",
      "\u001b[0m‚ú® Stop viewing logs with ^C\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m‚ú® Machine_Requested‚Ä¶ done\n",
      "\u001b[1m\u001b[36m‚≠ê\u001b[0m Building‚Ä¶ Machine acquired -- commencing runn[0m\u001b[0m^C\n",
      "\u001b[0m\n",
      "\u001b[0m‚ú® Your run is still running remotely.\n",
      "\u001b[0m‚ú® Use 'spell kill 144' to terminate your run\n",
      "\u001b[0m‚ú® Use 'spell logs 144' to view logs again\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell run --machine-type v100-spot \\\n",
    "    --github-url 'https://github.com/spellrun/spell-examples.git' \\\n",
    "    --github-ref 'train-resumable' \\\n",
    "    --mount uploads/segmented-bob-ross-images:/mnt/segmented-bob-ross-images \\\n",
    "    \"python spot/train_resumable.py --resume\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
